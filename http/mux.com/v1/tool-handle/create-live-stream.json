{
  "name": "create-live-stream",
  "description": "Creates a new live stream. Once created, an encoder can connect to Mux via the specified stream key and begin streaming to an audience.",
  "parameters": {
    "type": "object",
    "properties": {
      "body": {
        "$ref": "#/$defs/CreateLiveStreamRequest"
      }
    },
    "required": [
      "body"
    ],
    "$defs": {
      "CreateLiveStreamRequest": {
        "properties": {
          "audio_only": {
            "description": "Force the live stream to only process the audio track when the value is set to true. Mux drops the video track if broadcasted.",
            "type": "boolean"
          },
          "embedded_subtitles": {
            "description": "Describe the embedded closed caption contents of the incoming live stream.",
            "items": {
              "$ref": "#/$defs/LiveStreamEmbeddedSubtitleSettings"
            },
            "type": "array"
          },
          "generated_subtitles": {
            "description": "Configure the incoming live stream to include subtitles created with automatic speech recognition. Each Asset created from a live stream with `generated_subtitles` configured will automatically receive two text tracks. The first of these will have a `text_source` value of `generated_live`, and will be available with `ready` status as soon as the stream is live. The second text track will have a `text_source` value of `generated_live_final` and will contain subtitles with improved accuracy, timing, and formatting. However, `generated_live_final` tracks will not be available in `ready` status until the live stream ends. If an Asset has both `generated_live` and `generated_live_final` tracks that are `ready`, then only the `generated_live_final` track will be included during playback.",
            "items": {
              "$ref": "#/$defs/LiveStreamGeneratedSubtitleSettings"
            },
            "type": "array"
          },
          "latency_mode": {
            "description": "Latency is the time from when the streamer transmits a frame of video to when you see it in the player. Set this as an alternative to setting low latency or reduced latency flags. The Low Latency value is a beta feature. Read more here: https://mux.com/blog/introducing-low-latency-live-streaming/",
            "enum": [
              "low",
              "reduced",
              "standard"
            ],
            "type": "string",
            "x-mux-doc-decorators": [
              "public-beta"
            ]
          },
          "low_latency": {
            "deprecated": true,
            "description": "This field is deprecated. Please use `latency_mode` instead. Latency is the time from when the streamer transmits a frame of video to when you see it in the player. Setting this option will enable compatibility with the LL-HLS specification for low-latency streaming. This typically has lower latency than Reduced Latency streams, and cannot be combined with Reduced Latency.",
            "format": "boolean",
            "type": "boolean",
            "x-mux-doc-decorators": [
              "public-beta",
              "hidden"
            ]
          },
          "max_continuous_duration": {
            "$ref": "#/$defs/MaxContinuousDuration"
          },
          "new_asset_settings": {
            "$ref": "#/$defs/CreateAssetRequest"
          },
          "passthrough": {
            "type": "string"
          },
          "playback_policy": {
            "items": {
              "$ref": "#/$defs/PlaybackPolicy"
            },
            "type": "array"
          },
          "reconnect_slate_url": {
            "description": "The URL of the image file that Mux should download and use as slate media during interruptions of the live stream media. This file will be downloaded each time a new recorded asset is created from the live stream. If this is not set, the default slate media will be used.",
            "type": "string"
          },
          "reconnect_window": {
            "default": 60,
            "description": "When live streaming software disconnects from Mux, either intentionally or due to a drop in the network, the Reconnect Window is the time in seconds that Mux should wait for the streaming software to reconnect before considering the live stream finished and completing the recorded asset. Defaults to 60 seconds on the API if not specified.\n\nIf not specified directly, Standard Latency streams have a Reconnect Window of 60 seconds; Reduced and Low Latency streams have a default of 0 seconds, or no Reconnect Window. For that reason, we suggest specifying a value other than zero for Reduced and Low Latency streams.\n\nReduced and Low Latency streams with a Reconnect Window greater than zero will insert slate media into the recorded asset while waiting for the streaming software to reconnect or when there are brief interruptions in the live stream media. When using a Reconnect Window setting higher than 60 seconds with a Standard Latency stream, we highly recommend enabling slate with the `use_slate_for_standard_latency` option.\n",
            "format": "float",
            "maximum": 1800,
            "minimum": 0,
            "type": "number"
          },
          "reduced_latency": {
            "deprecated": true,
            "description": "This field is deprecated. Please use `latency_mode` instead. Latency is the time from when the streamer transmits a frame of video to when you see it in the player. Set this if you want lower latency for your live stream. Read more here: https://mux.com/blog/reduced-latency-for-mux-live-streaming-now-available/",
            "format": "boolean",
            "type": "boolean"
          },
          "simulcast_targets": {
            "items": {
              "$ref": "#/$defs/CreateSimulcastTargetRequest"
            },
            "type": "array"
          },
          "test": {
            "description": "Marks the live stream as a test live stream when the value is set to true. A test live stream can help evaluate the Mux Video APIs without incurring any cost. There is no limit on number of test live streams created. Test live streams are watermarked with the Mux logo and limited to 5 minutes. The test live stream is disabled after the stream is active for 5 mins and the recorded asset also deleted after 24 hours.",
            "format": "boolean",
            "type": "boolean"
          },
          "use_slate_for_standard_latency": {
            "default": false,
            "description": "By default, Standard Latency live streams do not have slate media inserted while waiting for live streaming software to reconnect to Mux. Setting this to true enables slate insertion on a Standard Latency stream.",
            "format": "boolean",
            "type": "boolean"
          }
        },
        "type": "object"
      },
      "LiveStreamEmbeddedSubtitleSettings": {
        "properties": {
          "language_channel": {
            "default": "cc1",
            "description": "CEA-608 caption channel to read data from.",
            "enum": [
              "cc1",
              "cc2",
              "cc3",
              "cc4"
            ],
            "type": "string"
          },
          "language_code": {
            "default": "en",
            "description": "The language of the closed caption stream. Value must be BCP 47 compliant.",
            "type": "string"
          },
          "name": {
            "description": "A name for this live stream closed caption track.",
            "type": "string"
          },
          "passthrough": {
            "description": "Arbitrary user-supplied metadata set for the live stream closed caption track. Max 255 characters.",
            "type": "string"
          }
        },
        "type": "object"
      },
      "LiveStreamGeneratedSubtitleSettings": {
        "properties": {
          "language_code": {
            "default": "en",
            "description": "The language to generate subtitles in.",
            "enum": [
              "en",
              "en-US"
            ],
            "type": "string"
          },
          "name": {
            "description": "A name for this live stream subtitle track.",
            "type": "string"
          },
          "passthrough": {
            "description": "Arbitrary metadata set for the live stream subtitle track. Max 255 characters.",
            "type": "string"
          },
          "transcription_vocabulary_ids": {
            "description": "Unique identifiers for existing Transcription Vocabularies to use while generating subtitles for the live stream. If the Transcription Vocabularies provided collectively have more than 1000 phrases, only the first 1000 phrases will be included.",
            "items": {
              "type": "string"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "MaxContinuousDuration": {
        "default": 43200,
        "description": "The time in seconds a live stream may be continuously active before being disconnected. Defaults to 12 hours.",
        "format": "int32",
        "maximum": 43200,
        "minimum": 60,
        "type": "integer"
      },
      "CreateAssetRequest": {
        "properties": {
          "encoding_tier": {
            "description": "The encoding tier informs the cost, quality, and available platform features for the asset. By default the `smart` encoding tier is used.",
            "enum": [
              "smart",
              "baseline"
            ],
            "type": "string",
            "x-mux-doc-decorators": [
              "hidden"
            ]
          },
          "input": {
            "description": "An array of objects that each describe an input file to be used to create the asset. As a shortcut, input can also be a string URL for a file when only one input file is used. See `input[].url` for requirements.",
            "items": {
              "$ref": "#/$defs/InputSettings"
            },
            "type": "array"
          },
          "master_access": {
            "description": "Specify what level (if any) of support for master access. Master access can be enabled temporarily for your asset to be downloaded. See the [Download your videos guide](/guides/video/download-your-videos) for more information.",
            "enum": [
              "none",
              "temporary"
            ],
            "type": "string"
          },
          "max_resolution_tier": {
            "description": "Max resolution tier can be used to control the maximum `resolution_tier` your asset is encoded, stored, and streamed at. If not set, this defaults to `1080p`.",
            "enum": [
              "1080p",
              "1440p",
              "2160p"
            ],
            "type": "string"
          },
          "mp4_support": {
            "description": "Specify what level (if any) of support for mp4 playback. In most cases you should use our default HLS-based streaming playback ({playback_id}.m3u8) which can automatically adjust to viewers' connection speeds, but an mp4 can be useful for some legacy devices or downloading for offline playback. See the [Download your videos guide](/guides/video/download-your-videos) for more information.",
            "enum": [
              "none",
              "standard"
            ],
            "type": "string"
          },
          "normalize_audio": {
            "default": false,
            "description": "Normalize the audio track loudness level. This parameter is only applicable to on-demand (not live) assets.",
            "format": "boolean",
            "type": "boolean"
          },
          "passthrough": {
            "description": "Arbitrary user-supplied metadata that will be included in the asset details and related webhooks. Can be used to store your own ID for a video along with the asset. **Max: 255 characters**.",
            "type": "string"
          },
          "per_title_encode": {
            "deprecated": true,
            "format": "boolean",
            "type": "boolean",
            "x-mux-doc-decorators": [
              "hidden"
            ]
          },
          "playback_policy": {
            "description": "An array of playback policy names that you want applied to this asset and available through `playback_ids`. Options include: `\"public\"` (anyone with the playback URL can stream the asset). And `\"signed\"` (an additional access token is required to play the asset). If no playback_policy is set, the asset will have no playback IDs and will therefore not be playable. For simplicity, a single string name can be used in place of the array in the case of only one playback policy.",
            "items": {
              "$ref": "#/$defs/PlaybackPolicy"
            },
            "type": "array"
          },
          "test": {
            "description": "Marks the asset as a test asset when the value is set to true. A Test asset can help evaluate the Mux Video APIs without incurring any cost. There is no limit on number of test assets created. Test asset are watermarked with the Mux logo, limited to 10 seconds, deleted after 24 hrs.",
            "format": "boolean",
            "type": "boolean"
          }
        },
        "type": "object"
      },
      "InputSettings": {
        "description": "An array of objects that each describe an input file to be used to create the asset. As a shortcut, `input` can also be a string URL for a file when only one input file is used. See `input[].url` for requirements.",
        "properties": {
          "closed_captions": {
            "description": "Indicates the track provides Subtitles for the Deaf or Hard-of-hearing (SDH). This optional parameter should be used for tracks with `type` of `text` and `text_type` set to `subtitles`.",
            "type": "boolean"
          },
          "end_time": {
            "description": "The time offset in seconds from the beginning of the video, indicating the clip's ending marker. The default value is the duration of the video when not included. This parameter is only applicable for creating clips when `input.url` has `mux://assets/{asset_id}` format.",
            "format": "double",
            "type": "number"
          },
          "generated_subtitles": {
            "description": "Generate subtitle tracks using automatic speech recognition using this configuration. This may only be provided for the first input object (the main input file). For direct uploads, this first input should omit the url parameter, as the main input file is provided via the direct upload. This will create subtitles based on the audio track ingested from that main input file. Note that subtitle generation happens after initial ingest, so the generated tracks will be in the `preparing` state when the asset transitions to `ready`.",
            "items": {
              "$ref": "#/$defs/AssetGeneratedSubtitleSettings"
            },
            "type": "array"
          },
          "language_code": {
            "description": "The language code value must be a valid [BCP 47](https://tools.ietf.org/html/bcp47) specification compliant value. For example, `en` for English or `en-US` for the US version of English. This parameter is required for `text` and `audio` track types.",
            "type": "string"
          },
          "name": {
            "description": "The name of the track containing a human-readable description. This value must be unique within each group of `text` or `audio` track types. The HLS manifest will associate a subtitle text track with this value. For example, the value should be \"English\" for a subtitle text track with `language_code` set to `en`. This optional parameter should be used only for `text` and `audio` type tracks. This parameter can be optionally provided for the first video input to denote the name of the muxed audio track if present. If this parameter is not included, Mux will auto-populate based on the `input[].language_code` value.",
            "type": "string"
          },
          "overlay_settings": {
            "description": "An object that describes how the image file referenced in URL should be placed over the video (i.e. watermarking). Ensure that the URL is active and persists the entire lifespan of the video object.",
            "properties": {
              "height": {
                "description": "How tall the overlay should appear. Can be expressed as a percent (\"10%\") or as a pixel value (\"100px\"). If both width and height are left blank the height will be the true pixels of the image, applied as if the video has been scaled to fit a 1920x1080 frame. If width is supplied with no height, the height will scale proportionally to the width.",
                "type": "string"
              },
              "horizontal_align": {
                "description": "Where the horizontal positioning of the overlay/watermark should begin from.",
                "enum": [
                  "left",
                  "center",
                  "right"
                ],
                "type": "string"
              },
              "horizontal_margin": {
                "description": "The distance from the horizontal_align starting point and the image's closest edge. Can be expressed as a percent (\"10%\") or as a pixel value (\"100px\"). Negative values will move the overlay offscreen. In the case of 'center', a positive value will shift the image towards the right and and a negative value will shift it towards the left.",
                "type": "string"
              },
              "opacity": {
                "description": "How opaque the overlay should appear, expressed as a percent. (Default 100%)",
                "type": "string"
              },
              "vertical_align": {
                "description": "Where the vertical positioning of the overlay/watermark should begin from. Defaults to `\"top\"`",
                "enum": [
                  "top",
                  "middle",
                  "bottom"
                ],
                "type": "string"
              },
              "vertical_margin": {
                "description": "The distance from the vertical_align starting point and the image's closest edge. Can be expressed as a percent (\"10%\") or as a pixel value (\"100px\"). Negative values will move the overlay offscreen. In the case of 'middle', a positive value will shift the overlay towards the bottom and and a negative value will shift it towards the top.",
                "type": "string"
              },
              "width": {
                "description": "How wide the overlay should appear. Can be expressed as a percent (\"10%\") or as a pixel value (\"100px\"). If both width and height are left blank the width will be the true pixels of the image, applied as if the video has been scaled to fit a 1920x1080 frame. If height is supplied with no width, the width will scale proportionally to the height.",
                "type": "string"
              }
            },
            "type": "object"
          },
          "passthrough": {
            "description": "This optional parameter should be used tracks with `type` of `text` and `text_type` set to `subtitles`.",
            "type": "string"
          },
          "start_time": {
            "description": "The time offset in seconds from the beginning of the video indicating the clip's starting marker. The default value is 0 when not included. This parameter is only applicable for creating clips when `input.url` has `mux://assets/{asset_id}` format.",
            "format": "double",
            "type": "number"
          },
          "text_type": {
            "description": "Type of text track. This parameter only supports subtitles value. For more information on Subtitles / Closed Captions, [see this blog post](https://mux.com/blog/subtitles-captions-webvtt-hls-and-those-magic-flags/). This parameter is required for `text` type tracks.",
            "enum": [
              "subtitles"
            ],
            "type": "string"
          },
          "type": {
            "description": "This parameter is required for `text` type tracks.",
            "enum": [
              "video",
              "audio",
              "text"
            ],
            "type": "string"
          },
          "url": {
            "description": "The URL of the file that Mux should download and use.\n* For the main input file, this should be the URL to the muxed file for Mux to download, for example an MP4, MOV, MKV, or TS file. Mux supports most audio/video file formats and codecs, but for fastest processing, you should [use standard inputs wherever possible](https://docs.mux.com/guides/video/minimize-processing-time).\n* For `audio` tracks, the URL is the location of the audio file for Mux to download, for example an M4A, WAV, or MP3 file. Mux supports most audio file formats and codecs, but for fastest processing, you should [use standard inputs wherever possible](https://docs.mux.com/guides/video/minimize-processing-time).\n* For `text` tracks, the URL is the location of subtitle/captions file. Mux supports [SubRip Text (SRT)](https://en.wikipedia.org/wiki/SubRip) and [Web Video Text Tracks](https://www.w3.org/TR/webvtt1/) formats for ingesting Subtitles and Closed Captions.\n* For Watermarking or Overlay, the URL is the location of the watermark image.\n* When creating clips from existing Mux assets, the URL is defined with `mux://assets/{asset_id}` template where `asset_id` is the Asset Identifier for creating the clip from.\nThe url property may be omitted on the first input object when providing asset settings for LiveStream and Upload objects, in order to configure settings related to the primary (live stream or direct upload) input.\n",
            "type": "string"
          }
        },
        "type": "object"
      },
      "AssetGeneratedSubtitleSettings": {
        "properties": {
          "language_code": {
            "default": "en",
            "description": "The language to generate subtitles in.",
            "enum": [
              "en",
              "en-US"
            ],
            "type": "string"
          },
          "name": {
            "description": "A name for this subtitle track.",
            "type": "string"
          },
          "passthrough": {
            "description": "Arbitrary metadata set for the subtitle track. Max 255 characters.",
            "type": "string"
          }
        },
        "type": "object"
      },
      "PlaybackPolicy": {
        "description": "* `public` playback IDs are accessible by constructing an HLS URL like `https://stream.mux.com/${PLAYBACK_ID}`\n\n* `signed` playback IDs should be used with tokens `https://stream.mux.com/${PLAYBACK_ID}?token={TOKEN}`. See [Secure video playback](https://docs.mux.com/guides/video/secure-video-playback) for details about creating tokens.\n",
        "enum": [
          "public",
          "signed"
        ],
        "type": "string"
      },
      "CreateSimulcastTargetRequest": {
        "properties": {
          "passthrough": {
            "description": "Arbitrary user-supplied metadata set by you when creating a simulcast target.",
            "type": "string"
          },
          "stream_key": {
            "description": "Stream Key represents a stream identifier on the third party live streaming service to send the parent live stream to.",
            "type": "string"
          },
          "url": {
            "description": "RTMP hostname including application name for the third party live streaming service. Example: `rtmp://live.example.com/app`.",
            "type": "string"
          }
        },
        "required": [
          "url"
        ],
        "type": "object"
      }
    }
  },
  "handler": "http",
  "request": {
    "method": "POST",
    "url": {
      "$uri": "https://api.mux.com/video/v1/live-streams"
    },
    "body": {
      "$": "body",
      "encode": "json"
    }
  },
  "responses": {
    "201": {
      "$encode": "markdown",
      "$block": [
        {
          "$h1": "Object"
        },
        "**Key properties:**",
        {
          "$ul": [
            [
              "**data**",
              {
                "$ul": [
                  "**active_asset_id**: The Asset that is currently being created if there is an active broadcast.",
                  "**audio_only**: The live stream only processes the audio track if the value is set to true. Mux drops the video track if broadcasted.",
                  "**created_at**: Time the Live Stream was created, defined as a Unix timestamp (seconds since epoch).",
                  "**embedded_subtitles**: Describes the embedded closed caption configuration of the incoming live stream.",
                  "**generated_subtitles**: Configure the incoming live stream to include subtitles created with automatic speech recognition. Each Asset created from a live stream with `generated_subtitles` configured will automatically receive two text tracks. The first of these will have a `text_source` value of `generated_live`, and will be available with `ready` status as soon as the stream is live. The second text track will have a `text_source` value of `generated_live_final` and will contain subtitles with improved accuracy, timing, and formatting. However, `generated_live_final` tracks will not be available in `ready` status until the live stream ends. If an Asset has both `generated_live` and `generated_live_final` tracks that are `ready`, then only the `generated_live_final` track will be included during playback.",
                  "**id**: Unique identifier for the Live Stream. Max 255 characters.",
                  "**latency_mode**: Latency is the time from when the streamer transmits a frame of video to when you see it in the player. Set this as an alternative to setting low latency or reduced latency flags. The Low Latency value is a beta feature. Read more here: https://mux.com/blog/introducing-low-latency-live-streaming/",
                  "**low_latency**: This field is deprecated. Please use `latency_mode` instead. Latency is the time from when the streamer transmits a frame of video to when you see it in the player. Setting this option will enable compatibility with the LL-HLS specification for low-latency streaming. This typically has lower latency than Reduced Latency streams, and cannot be combined with Reduced Latency.",
                  "**max_continuous_duration**: The time in seconds a live stream may be continuously active before being disconnected. Defaults to 12 hours. (default: 43200)",
                  [
                    "**new_asset_settings**",
                    {
                      "$ul": [
                        "**encoding_tier**: The encoding tier informs the cost, quality, and available platform features for the asset. By default the `smart` encoding tier is used.",
                        "**input**: An array of objects that each describe an input file to be used to create the asset. As a shortcut, input can also be a string URL for a file when only one input file is used. See `input[].url` for requirements.",
                        "**master_access**: Specify what level (if any) of support for master access. Master access can be enabled temporarily for your asset to be downloaded. See the [Download your videos guide](/guides/video/download-your-videos) for more information.",
                        "**max_resolution_tier**: Max resolution tier can be used to control the maximum `resolution_tier` your asset is encoded, stored, and streamed at. If not set, this defaults to `1080p`.",
                        "**mp4_support**: Specify what level (if any) of support for mp4 playback. In most cases you should use our default HLS-based streaming playback ({playback_id}.m3u8) which can automatically adjust to viewers' connection speeds, but an mp4 can be useful for some legacy devices or downloading for offline playback. See the [Download your videos guide](/guides/video/download-your-videos) for more information.",
                        "**normalize_audio**: Normalize the audio track loudness level. This parameter is only applicable to on-demand (not live) assets. (default: false)",
                        "**passthrough**: Arbitrary user-supplied metadata that will be included in the asset details and related webhooks. Can be used to store your own ID for a video along with the asset. **Max: 255 characters**.",
                        "**per_title_encode**",
                        "**playback_policy**: An array of playback policy names that you want applied to this asset and available through `playback_ids`. Options include: `\"public\"` (anyone with the playback URL can stream the asset). And `\"signed\"` (an additional access token is required to play the asset). If no playback_policy is set, the asset will have no playback IDs and will therefore not be playable. For simplicity, a single string name can be used in place of the array in the case of only one playback policy.",
                        "**test**: Marks the asset as a test asset when the value is set to true. A Test asset can help evaluate the Mux Video APIs without incurring any cost. There is no limit on number of test assets created. Test asset are watermarked with the Mux logo, limited to 10 seconds, deleted after 24 hrs."
                      ]
                    }
                  ],
                  "**passthrough**: Arbitrary user-supplied metadata set for the asset. Max 255 characters.",
                  "**playback_ids**: An array of Playback ID objects. Use these to create HLS playback URLs. See [Play your videos](https://docs.mux.com/guides/video/play-your-videos) for more details.",
                  "**recent_asset_ids**: An array of strings with the most recent Asset IDs that were created from this Live Stream. The most recently generated Asset ID is the last entry in the list.",
                  "**reconnect_slate_url**: The URL of the image file that Mux should download and use as slate media during interruptions of the live stream media. This file will be downloaded each time a new recorded asset is created from the live stream. If this is not set, the default slate media will be used.",
                  "**reconnect_window**: When live streaming software disconnects from Mux, either intentionally or due to a drop in the network, the Reconnect Window is the time in seconds that Mux should wait for the streaming software to reconnect before considering the live stream finished and completing the recorded asset. **Max**: 1800s (30 minutes). (default: 60)",
                  "**reduced_latency**: This field is deprecated. Please use `latency_mode` instead. Latency is the time from when the streamer transmits a frame of video to when you see it in the player. Set this if you want lower latency for your live stream. See the [Reduce live stream latency guide](https://docs.mux.com/guides/video/reduce-live-stream-latency) to understand the tradeoffs.",
                  "**simulcast_targets**: Each Simulcast Target contains configuration details to broadcast (or \"restream\") a live stream to a third-party streaming service. [See the Stream live to 3rd party platforms guide](https://docs.mux.com/guides/video/stream-live-to-3rd-party-platforms).",
                  "**status**: `idle` indicates that there is no active broadcast. `active` indicates that there is an active broadcast and `disabled` status indicates that no future RTMP streams can be published.",
                  "**stream_key**: Unique key used for streaming to a Mux RTMP endpoint. This should be considered as sensitive as credentials, anyone with this stream key can begin streaming.",
                  "**test**: True means this live stream is a test live stream. Test live streams can be used to help evaluate the Mux Video APIs for free. There is no limit on the number of test live streams, but they are watermarked with the Mux logo, and limited to 5 minutes. The test live stream is disabled after the stream is active for 5 mins and the recorded asset also deleted after 24 hours.",
                  "**use_slate_for_standard_latency**: By default, Standard Latency live streams do not have slate media inserted while waiting for live streaming software to reconnect to Mux. Setting this to true enables slate insertion on a Standard Latency stream. (default: false)"
                ]
              }
            ]
          ]
        },
        {
          "$lang": "json",
          "$code": {
            "$encode": "json",
            "$indent": true,
            "$content": {
              "$": "$.body"
            }
          }
        }
      ]
    }
  }
}
