{
  "name": "spanner_projects_instances_databases_sessions_executeSql",
  "description": "Executes an SQL statement, returning all results in a single reply. This method cannot be used to return a result set larger than 10 MiB; if the query yields more data than that, the query fails with a `FAILED_PRECONDITION` error. Operations inside read-write transactions might return `ABORTED`. If this occurs, the application should restart the transaction from the beginning. See Transaction for more details. Larger result sets can be fetched in streaming fashion by calling ExecuteStreamingSql instead.",
  "parameters": {
    "type": "object",
    "properties": {
      "session": {
        "type": "string",
        "description": "Required. The session in which the SQL query should be performed."
      },
      "$.xgafv": {
        "enum": [
          "1",
          "2"
        ],
        "type": "string",
        "description": "V1 error format."
      },
      "access_token": {
        "type": "string",
        "description": "OAuth access token."
      },
      "alt": {
        "enum": [
          "json",
          "media",
          "proto"
        ],
        "type": "string",
        "description": "Data format for response."
      },
      "callback": {
        "type": "string",
        "description": "JSONP"
      },
      "fields": {
        "type": "string",
        "description": "Selector specifying which fields to include in a partial response."
      },
      "key": {
        "type": "string",
        "description": "API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token."
      },
      "oauth_token": {
        "type": "string",
        "description": "OAuth 2.0 token for the current user."
      },
      "prettyPrint": {
        "type": "boolean",
        "description": "Returns response with indentations and line breaks."
      },
      "quotaUser": {
        "type": "string",
        "description": "Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters."
      },
      "upload_protocol": {
        "type": "string",
        "description": "Upload protocol for media (e.g. \"raw\", \"multipart\")."
      },
      "uploadType": {
        "type": "string",
        "description": "Legacy upload protocol for media (e.g. \"media\", \"multipart\")."
      },
      "body": {
        "$ref": "#/$defs/ExecuteSqlRequest"
      }
    },
    "required": [
      "session"
    ],
    "$defs": {
      "ExecuteSqlRequest": {
        "description": "The request for ExecuteSql and ExecuteStreamingSql.",
        "properties": {
          "dataBoostEnabled": {
            "description": "If this is for a partitioned query and this field is set to `true`, the request is executed with Spanner Data Boost independent compute resources. If the field is set to `true` but the request does not set `partition_token`, the API returns an `INVALID_ARGUMENT` error.",
            "type": "boolean"
          },
          "directedReadOptions": {
            "$ref": "#/$defs/DirectedReadOptions"
          },
          "paramTypes": {
            "additionalProperties": {
              "$ref": "#/$defs/Type"
            },
            "description": "It is not always possible for Cloud Spanner to infer the right SQL type from a JSON value. For example, values of type `BYTES` and values of type `STRING` both appear in params as JSON strings. In these cases, `param_types` can be used to specify the exact SQL type for some or all of the SQL statement parameters. See the definition of Type for more information about SQL types.",
            "type": "object"
          },
          "params": {
            "additionalProperties": {
              "description": "Properties of the object."
            },
            "description": "Parameter names and values that bind to placeholders in the SQL string. A parameter placeholder consists of the `@` character followed by the parameter name (for example, `@firstName`). Parameter names must conform to the naming requirements of identifiers as specified at https://cloud.google.com/spanner/docs/lexical#identifiers. Parameters can appear anywhere that a literal value is expected. The same parameter name can be used more than once, for example: `\"WHERE id > @msg_id AND id < @msg_id + 100\"` It is an error to execute a SQL statement with unbound parameters.",
            "type": "object"
          },
          "partitionToken": {
            "description": "If present, results will be restricted to the specified partition previously created using PartitionQuery(). There must be an exact match for the values of fields common to this message and the PartitionQueryRequest message used to create this partition_token.",
            "format": "byte",
            "type": "string"
          },
          "queryMode": {
            "description": "Used to control the amount of debugging information returned in ResultSetStats. If partition_token is set, query_mode can only be set to QueryMode.NORMAL.",
            "enum": [
              "NORMAL",
              "PLAN",
              "PROFILE"
            ],
            "type": "string"
          },
          "queryOptions": {
            "$ref": "#/$defs/QueryOptions"
          },
          "requestOptions": {
            "$ref": "#/$defs/RequestOptions"
          },
          "resumeToken": {
            "description": "If this request is resuming a previously interrupted SQL statement execution, `resume_token` should be copied from the last PartialResultSet yielded before the interruption. Doing this enables the new SQL statement execution to resume where the last one left off. The rest of the request parameters must exactly match the request that yielded this token.",
            "format": "byte",
            "type": "string"
          },
          "seqno": {
            "description": "A per-transaction sequence number used to identify this request. This field makes each request idempotent such that if the request is received multiple times, at most one will succeed. The sequence number must be monotonically increasing within the transaction. If a request arrives for the first time with an out-of-order sequence number, the transaction may be aborted. Replays of previously handled requests will yield the same response as the first execution. Required for DML statements. Ignored for queries.",
            "format": "int64",
            "type": "string"
          },
          "sql": {
            "description": "Required. The SQL string.",
            "type": "string"
          },
          "transaction": {
            "$ref": "#/$defs/TransactionSelector"
          }
        },
        "type": "object"
      },
      "DirectedReadOptions": {
        "description": "The DirectedReadOptions can be used to indicate which replicas or regions should be used for non-transactional reads or queries. DirectedReadOptions may only be specified for a read-only transaction, otherwise the API will return an `INVALID_ARGUMENT` error.",
        "properties": {
          "excludeReplicas": {
            "$ref": "#/$defs/ExcludeReplicas"
          },
          "includeReplicas": {
            "$ref": "#/$defs/IncludeReplicas"
          }
        },
        "type": "object"
      },
      "ExcludeReplicas": {
        "description": "An ExcludeReplicas contains a repeated set of ReplicaSelection that should be excluded from serving requests.",
        "properties": {
          "replicaSelections": {
            "description": "The directed read replica selector.",
            "items": {
              "$ref": "#/$defs/ReplicaSelection"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "ReplicaSelection": {
        "description": "The directed read replica selector. Callers must provide one or more of the following fields for replica selection: * `location` - The location must be one of the regions within the multi-region configuration of your database. * `type` - The type of the replica. Some examples of using replica_selectors are: * `location:us-east1` --> The \"us-east1\" replica(s) of any available type will be used to process the request. * `type:READ_ONLY` --> The \"READ_ONLY\" type replica(s) in nearest available location will be used to process the request. * `location:us-east1 type:READ_ONLY` --> The \"READ_ONLY\" type replica(s) in location \"us-east1\" will be used to process the request.",
        "properties": {
          "location": {
            "description": "The location or region of the serving requests, e.g. \"us-east1\".",
            "type": "string"
          },
          "type": {
            "description": "The type of replica.",
            "enum": [
              "TYPE_UNSPECIFIED",
              "READ_WRITE",
              "READ_ONLY"
            ],
            "type": "string"
          }
        },
        "type": "object"
      },
      "IncludeReplicas": {
        "description": "An IncludeReplicas contains a repeated set of ReplicaSelection which indicates the order in which replicas should be considered.",
        "properties": {
          "autoFailoverDisabled": {
            "description": "If true, Spanner will not route requests to a replica outside the include_replicas list when all of the specified replicas are unavailable or unhealthy. Default value is `false`.",
            "type": "boolean"
          },
          "replicaSelections": {
            "description": "The directed read replica selector.",
            "items": {
              "$ref": "#/$defs/ReplicaSelection"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "Type": {
        "description": "`Type` indicates the type of a Cloud Spanner value, as might be stored in a table cell or returned from an SQL query.",
        "properties": {
          "arrayElementType": {
            "$ref": "#/$defs/Type"
          },
          "code": {
            "description": "Required. The TypeCode for this type.",
            "enum": [
              "TYPE_CODE_UNSPECIFIED",
              "BOOL",
              "INT64",
              "FLOAT64",
              "FLOAT32",
              "TIMESTAMP",
              "DATE",
              "STRING",
              "BYTES",
              "ARRAY",
              "STRUCT",
              "NUMERIC",
              "JSON",
              "PROTO",
              "ENUM"
            ],
            "type": "string"
          },
          "protoTypeFqn": {
            "description": "If code == PROTO or code == ENUM, then `proto_type_fqn` is the fully qualified name of the proto type representing the proto/enum definition.",
            "type": "string"
          },
          "structType": {
            "$ref": "#/$defs/StructType"
          },
          "typeAnnotation": {
            "description": "The TypeAnnotationCode that disambiguates SQL type that Spanner will use to represent values of this type during query processing. This is necessary for some type codes because a single TypeCode can be mapped to different SQL types depending on the SQL dialect. type_annotation typically is not needed to process the content of a value (it doesn't affect serialization) and clients can ignore it on the read path.",
            "enum": [
              "TYPE_ANNOTATION_CODE_UNSPECIFIED",
              "PG_NUMERIC",
              "PG_JSONB"
            ],
            "type": "string"
          }
        },
        "type": "object"
      },
      "StructType": {
        "description": "`StructType` defines the fields of a STRUCT type.",
        "properties": {
          "fields": {
            "description": "The list of fields that make up this struct. Order is significant, because values of this struct type are represented as lists, where the order of field values matches the order of fields in the StructType. In turn, the order of fields matches the order of columns in a read request, or the order of fields in the `SELECT` clause of a query.",
            "items": {
              "$ref": "#/$defs/Field"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "Field": {
        "description": "Message representing a single field of a struct.",
        "properties": {
          "name": {
            "description": "The name of the field. For reads, this is the column name. For SQL queries, it is the column alias (e.g., `\"Word\"` in the query `\"SELECT 'hello' AS Word\"`), or the column name (e.g., `\"ColName\"` in the query `\"SELECT ColName FROM Table\"`). Some columns might have an empty name (e.g., `\"SELECT UPPER(ColName)\"`). Note that a query result can contain multiple fields with the same name.",
            "type": "string"
          },
          "type": {
            "$ref": "#/$defs/Type"
          }
        },
        "type": "object"
      },
      "QueryOptions": {
        "description": "Query optimizer configuration.",
        "properties": {
          "optimizerStatisticsPackage": {
            "description": "An option to control the selection of optimizer statistics package. This parameter allows individual queries to use a different query optimizer statistics package. Specifying `latest` as a value instructs Cloud Spanner to use the latest generated statistics package. If not specified, Cloud Spanner uses the statistics package set at the database level options, or the latest package if the database option is not set. The statistics package requested by the query has to be exempt from garbage collection. This can be achieved with the following DDL statement: ``` ALTER STATISTICS SET OPTIONS (allow_gc=false) ``` The list of available statistics packages can be queried from `INFORMATION_SCHEMA.SPANNER_STATISTICS`. Executing a SQL statement with an invalid optimizer statistics package or with a statistics package that allows garbage collection fails with an `INVALID_ARGUMENT` error.",
            "type": "string"
          },
          "optimizerVersion": {
            "description": "An option to control the selection of optimizer version. This parameter allows individual queries to pick different query optimizer versions. Specifying `latest` as a value instructs Cloud Spanner to use the latest supported query optimizer version. If not specified, Cloud Spanner uses the optimizer version set at the database level options. Any other positive integer (from the list of supported optimizer versions) overrides the default optimizer version for query execution. The list of supported optimizer versions can be queried from SPANNER_SYS.SUPPORTED_OPTIMIZER_VERSIONS. Executing a SQL statement with an invalid optimizer version fails with an `INVALID_ARGUMENT` error. See https://cloud.google.com/spanner/docs/query-optimizer/manage-query-optimizer for more information on managing the query optimizer. The `optimizer_version` statement hint has precedence over this setting.",
            "type": "string"
          }
        },
        "type": "object"
      },
      "RequestOptions": {
        "description": "Common request options for various APIs.",
        "properties": {
          "priority": {
            "description": "Priority for the request.",
            "enum": [
              "PRIORITY_UNSPECIFIED",
              "PRIORITY_LOW",
              "PRIORITY_MEDIUM",
              "PRIORITY_HIGH"
            ],
            "type": "string"
          },
          "requestTag": {
            "description": "A per-request tag which can be applied to queries or reads, used for statistics collection. Both request_tag and transaction_tag can be specified for a read or query that belongs to a transaction. This field is ignored for requests where it's not applicable (e.g. CommitRequest). Legal characters for `request_tag` values are all printable characters (ASCII 32 - 126) and the length of a request_tag is limited to 50 characters. Values that exceed this limit are truncated. Any leading underscore (_) characters will be removed from the string.",
            "type": "string"
          },
          "transactionTag": {
            "description": "A tag used for statistics collection about this transaction. Both request_tag and transaction_tag can be specified for a read or query that belongs to a transaction. The value of transaction_tag should be the same for all requests belonging to the same transaction. If this request doesn't belong to any transaction, transaction_tag will be ignored. Legal characters for `transaction_tag` values are all printable characters (ASCII 32 - 126) and the length of a transaction_tag is limited to 50 characters. Values that exceed this limit are truncated. Any leading underscore (_) characters will be removed from the string.",
            "type": "string"
          }
        },
        "type": "object"
      },
      "TransactionSelector": {
        "description": "This message is used to select the transaction in which a Read or ExecuteSql call runs. See TransactionOptions for more information about transactions.",
        "properties": {
          "begin": {
            "$ref": "#/$defs/TransactionOptions"
          },
          "id": {
            "description": "Execute the read or SQL query in a previously-started transaction.",
            "format": "byte",
            "type": "string"
          },
          "singleUse": {
            "$ref": "#/$defs/TransactionOptions"
          }
        },
        "type": "object"
      },
      "TransactionOptions": {
        "description": "Transactions: Each session can have at most one active transaction at a time (note that standalone reads and queries use a transaction internally and do count towards the one transaction limit). After the active transaction is completed, the session can immediately be re-used for the next transaction. It is not necessary to create a new session for each transaction. Transaction modes: Cloud Spanner supports three transaction modes: 1. Locking read-write. This type of transaction is the only way to write data into Cloud Spanner. These transactions rely on pessimistic locking and, if necessary, two-phase commit. Locking read-write transactions may abort, requiring the application to retry. 2. Snapshot read-only. Snapshot read-only transactions provide guaranteed consistency across several reads, but do not allow writes. Snapshot read-only transactions can be configured to read at timestamps in the past, or configured to perform a strong read (where Spanner will select a timestamp such that the read is guaranteed to see the effects of all transactions that have committed before the start of the read). Snapshot read-only transactions do not need to be committed. Queries on change streams must be performed with the snapshot read-only transaction mode, specifying a strong read. Please see TransactionOptions.ReadOnly.strong for more details. 3. Partitioned DML. This type of transaction is used to execute a single Partitioned DML statement. Partitioned DML partitions the key space and runs the DML statement over each partition in parallel using separate, internal transactions that commit independently. Partitioned DML transactions do not need to be committed. For transactions that only read, snapshot read-only transactions provide simpler semantics and are almost always faster. In particular, read-only transactions do not take locks, so they do not conflict with read-write transactions. As a consequence of not taking locks, they also do not abort, so retry loops are not needed. Transactions may only read-write data in a single database. They may, however, read-write data in different tables within that database. Locking read-write transactions: Locking transactions may be used to atomically read-modify-write data anywhere in a database. This type of transaction is externally consistent. Clients should attempt to minimize the amount of time a transaction is active. Faster transactions commit with higher probability and cause less contention. Cloud Spanner attempts to keep read locks active as long as the transaction continues to do reads, and the transaction has not been terminated by Commit or Rollback. Long periods of inactivity at the client may cause Cloud Spanner to release a transaction's locks and abort it. Conceptually, a read-write transaction consists of zero or more reads or SQL statements followed by Commit. At any time before Commit, the client can send a Rollback request to abort the transaction. Semantics: Cloud Spanner can commit the transaction if all read locks it acquired are still valid at commit time, and it is able to acquire write locks for all writes. Cloud Spanner can abort the transaction for any reason. If a commit attempt returns `ABORTED`, Cloud Spanner guarantees that the transaction has not modified any user data in Cloud Spanner. Unless the transaction commits, Cloud Spanner makes no guarantees about how long the transaction's locks were held for. It is an error to use Cloud Spanner locks for any sort of mutual exclusion other than between Cloud Spanner transactions themselves. Retrying aborted transactions: When a transaction aborts, the application can choose to retry the whole transaction again. To maximize the chances of successfully committing the retry, the client should execute the retry in the same session as the original attempt. The original session's lock priority increases with each consecutive abort, meaning that each attempt has a slightly better chance of success than the previous. Under some circumstances (for example, many transactions attempting to modify the same row(s)), a transaction can abort many times in a short period before successfully committing. Thus, it is not a good idea to cap the number of retries a transaction can attempt; instead, it is better to limit the total amount of time spent retrying. Idle transactions: A transaction is considered idle if it has no outstanding reads or SQL queries and has not started a read or SQL query within the last 10 seconds. Idle transactions can be aborted by Cloud Spanner so that they don't hold on to locks indefinitely. If an idle transaction is aborted, the commit will fail with error `ABORTED`. If this behavior is undesirable, periodically executing a simple SQL query in the transaction (for example, `SELECT 1`) prevents the transaction from becoming idle. Snapshot read-only transactions: Snapshot read-only transactions provides a simpler method than locking read-write transactions for doing several consistent reads. However, this type of transaction does not support writes. Snapshot transactions do not take locks. Instead, they work by choosing a Cloud Spanner timestamp, then executing all reads at that timestamp. Since they do not acquire locks, they do not block concurrent read-write transactions. Unlike locking read-write transactions, snapshot read-only transactions never abort. They can fail if the chosen read timestamp is garbage collected; however, the default garbage collection policy is generous enough that most applications do not need to worry about this in practice. Snapshot read-only transactions do not need to call Commit or Rollback (and in fact are not permitted to do so). To execute a snapshot transaction, the client specifies a timestamp bound, which tells Cloud Spanner how to choose a read timestamp. The types of timestamp bound are: - Strong (the default). - Bounded staleness. - Exact staleness. If the Cloud Spanner database to be read is geographically distributed, stale read-only transactions can execute more quickly than strong or read-write transactions, because they are able to execute far from the leader replica. Each type of timestamp bound is discussed in detail below. Strong: Strong reads are guaranteed to see the effects of all transactions that have committed before the start of the read. Furthermore, all rows yielded by a single read are consistent with each other -- if any part of the read observes a transaction, all parts of the read see the transaction. Strong reads are not repeatable: two consecutive strong read-only transactions might return inconsistent results if there are concurrent writes. If consistency across reads is required, the reads should be executed within a transaction or at an exact read timestamp. Queries on change streams (see below for more details) must also specify the strong read timestamp bound. See TransactionOptions.ReadOnly.strong. Exact staleness: These timestamp bounds execute reads at a user-specified timestamp. Reads at a timestamp are guaranteed to see a consistent prefix of the global transaction history: they observe modifications done by all transactions with a commit timestamp less than or equal to the read timestamp, and observe none of the modifications done by transactions with a larger commit timestamp. They will block until all conflicting transactions that may be assigned commit timestamps <= the read timestamp have finished. The timestamp can either be expressed as an absolute Cloud Spanner commit timestamp or a staleness relative to the current time. These modes do not require a \"negotiation phase\" to pick a timestamp. As a result, they execute slightly faster than the equivalent boundedly stale concurrency modes. On the other hand, boundedly stale reads usually return fresher results. See TransactionOptions.ReadOnly.read_timestamp and TransactionOptions.ReadOnly.exact_staleness. Bounded staleness: Bounded staleness modes allow Cloud Spanner to pick the read timestamp, subject to a user-provided staleness bound. Cloud Spanner chooses the newest timestamp within the staleness bound that allows execution of the reads at the closest available replica without blocking. All rows yielded are consistent with each other -- if any part of the read observes a transaction, all parts of the read see the transaction. Boundedly stale reads are not repeatable: two stale reads, even if they use the same staleness bound, can execute at different timestamps and thus return inconsistent results. Boundedly stale reads execute in two phases: the first phase negotiates a timestamp among all replicas needed to serve the read. In the second phase, reads are executed at the negotiated timestamp. As a result of the two phase execution, bounded staleness reads are usually a little slower than comparable exact staleness reads. However, they are typically able to return fresher results, and are more likely to execute at the closest replica. Because the timestamp negotiation requires up-front knowledge of which rows will be read, it can only be used with single-use read-only transactions. See TransactionOptions.ReadOnly.max_staleness and TransactionOptions.ReadOnly.min_read_timestamp. Old read timestamps and garbage collection: Cloud Spanner continuously garbage collects deleted and overwritten data in the background to reclaim storage space. This process is known as \"version GC\". By default, version GC reclaims versions after they are one hour old. Because of this, Cloud Spanner cannot perform reads at read timestamps more than one hour in the past. This restriction also applies to in-progress reads and/or SQL queries whose timestamp become too old while executing. Reads and SQL queries with too-old read timestamps fail with the error `FAILED_PRECONDITION`. You can configure and extend the `VERSION_RETENTION_PERIOD` of a database up to a period as long as one week, which allows Cloud Spanner to perform reads up to one week in the past. Querying change Streams: A Change Stream is a schema object that can be configured to watch data changes on the entire database, a set of tables, or a set of columns in a database. When a change stream is created, Spanner automatically defines a corresponding SQL Table-Valued Function (TVF) that can be used to query the change records in the associated change stream using the ExecuteStreamingSql API. The name of the TVF for a change stream is generated from the name of the change stream: READ_. All queries on change stream TVFs must be executed using the ExecuteStreamingSql API with a single-use read-only transaction with a strong read-only timestamp_bound. The change stream TVF allows users to specify the start_timestamp and end_timestamp for the time range of interest. All change records within the retention period is accessible using the strong read-only timestamp_bound. All other TransactionOptions are invalid for change stream queries. In addition, if TransactionOptions.read_only.return_read_timestamp is set to true, a special value of 2^63 - 2 will be returned in the Transaction message that describes the transaction, instead of a valid read timestamp. This special value should be discarded and not used for any subsequent queries. Please see https://cloud.google.com/spanner/docs/change-streams for more details on how to query the change stream TVFs. Partitioned DML transactions: Partitioned DML transactions are used to execute DML statements with a different execution strategy that provides different, and often better, scalability properties for large, table-wide operations than DML in a ReadWrite transaction. Smaller scoped statements, such as an OLTP workload, should prefer using ReadWrite transactions. Partitioned DML partitions the keyspace and runs the DML statement on each partition in separate, internal transactions. These transactions commit automatically when complete, and run independently from one another. To reduce lock contention, this execution strategy only acquires read locks on rows that match the WHERE clause of the statement. Additionally, the smaller per-partition transactions hold locks for less time. That said, Partitioned DML is not a drop-in replacement for standard DML used in ReadWrite transactions. - The DML statement must be fully-partitionable. Specifically, the statement must be expressible as the union of many statements which each access only a single row of the table. - The statement is not applied atomically to all rows of the table. Rather, the statement is applied atomically to partitions of the table, in independent transactions. Secondary index rows are updated atomically with the base table rows. - Partitioned DML does not guarantee exactly-once execution semantics against a partition. The statement will be applied at least once to each partition. It is strongly recommended that the DML statement should be idempotent to avoid unexpected results. For instance, it is potentially dangerous to run a statement such as `UPDATE table SET column = column + 1` as it could be run multiple times against some rows. - The partitions are committed automatically - there is no support for Commit or Rollback. If the call returns an error, or if the client issuing the ExecuteSql call dies, it is possible that some rows had the statement executed on them successfully. It is also possible that statement was never executed against other rows. - Partitioned DML transactions may only contain the execution of a single DML statement via ExecuteSql or ExecuteStreamingSql. - If any error is encountered during the execution of the partitioned DML operation (for instance, a UNIQUE INDEX violation, division by zero, or a value that cannot be stored due to schema constraints), then the operation is stopped at that point and an error is returned. It is possible that at this point, some partitions have been committed (or even committed multiple times), and other partitions have not been run at all. Given the above, Partitioned DML is good fit for large, database-wide, operations that are idempotent, such as deleting old rows from a very large table.",
        "properties": {
          "partitionedDml": {
            "$ref": "#/$defs/PartitionedDml"
          },
          "readOnly": {
            "$ref": "#/$defs/ReadOnly"
          },
          "readWrite": {
            "$ref": "#/$defs/ReadWrite"
          }
        },
        "type": "object"
      },
      "PartitionedDml": {
        "description": "Message type to initiate a Partitioned DML transaction.",
        "properties": {},
        "type": "object"
      },
      "ReadOnly": {
        "description": "Message type to initiate a read-only transaction.",
        "properties": {
          "exactStaleness": {
            "description": "Executes all reads at a timestamp that is `exact_staleness` old. The timestamp is chosen soon after the read is started. Guarantees that all writes that have committed more than the specified number of seconds ago are visible. Because Cloud Spanner chooses the exact timestamp, this mode works even if the client's local clock is substantially skewed from Cloud Spanner commit timestamps. Useful for reading at nearby replicas without the distributed timestamp negotiation overhead of `max_staleness`.",
            "format": "google-duration",
            "type": "string"
          },
          "maxStaleness": {
            "description": "Read data at a timestamp >= `NOW - max_staleness` seconds. Guarantees that all writes that have committed more than the specified number of seconds ago are visible. Because Cloud Spanner chooses the exact timestamp, this mode works even if the client's local clock is substantially skewed from Cloud Spanner commit timestamps. Useful for reading the freshest data available at a nearby replica, while bounding the possible staleness if the local replica has fallen behind. Note that this option can only be used in single-use transactions.",
            "format": "google-duration",
            "type": "string"
          },
          "minReadTimestamp": {
            "description": "Executes all reads at a timestamp >= `min_read_timestamp`. This is useful for requesting fresher data than some previous read, or data that is fresh enough to observe the effects of some previously committed transaction whose timestamp is known. Note that this option can only be used in single-use transactions. A timestamp in RFC3339 UTC \\\"Zulu\\\" format, accurate to nanoseconds. Example: `\"2014-10-02T15:01:23.045123456Z\"`.",
            "format": "google-datetime",
            "type": "string"
          },
          "readTimestamp": {
            "description": "Executes all reads at the given timestamp. Unlike other modes, reads at a specific timestamp are repeatable; the same read at the same timestamp always returns the same data. If the timestamp is in the future, the read will block until the specified timestamp, modulo the read's deadline. Useful for large scale consistent reads such as mapreduces, or for coordinating many reads against a consistent snapshot of the data. A timestamp in RFC3339 UTC \\\"Zulu\\\" format, accurate to nanoseconds. Example: `\"2014-10-02T15:01:23.045123456Z\"`.",
            "format": "google-datetime",
            "type": "string"
          },
          "returnReadTimestamp": {
            "description": "If true, the Cloud Spanner-selected read timestamp is included in the Transaction message that describes the transaction.",
            "type": "boolean"
          },
          "strong": {
            "description": "Read at a timestamp where all previously committed transactions are visible.",
            "type": "boolean"
          }
        },
        "type": "object"
      },
      "ReadWrite": {
        "description": "Message type to initiate a read-write transaction. Currently this transaction type has no options.",
        "properties": {
          "readLockMode": {
            "description": "Read lock mode for the transaction.",
            "enum": [
              "READ_LOCK_MODE_UNSPECIFIED",
              "PESSIMISTIC",
              "OPTIMISTIC"
            ],
            "type": "string"
          }
        },
        "type": "object"
      }
    }
  },
  "handler": "http",
  "request": {
    "method": "POST",
    "url": {
      "$uri": "https://spanner.googleapis.com//v1/{session}:executeSql{?$.xgafv,access_token,alt,callback,fields,key,oauth_token,prettyPrint,quotaUser,upload_protocol,uploadType}"
    },
    "body": {
      "$": "body",
      "encode": "json"
    }
  },
  "responses": {
    "200": {
      "$encode": "markdown",
      "$block": [
        {
          "$h1": "Object"
        },
        "Results from Read or ExecuteSql.",
        "**Key properties:**",
        {
          "$ul": [
            [
              "**metadata**: Metadata about a ResultSet or PartialResultSet.",
              {
                "$ul": [
                  [
                    "**rowType**: `StructType` defines the fields of a STRUCT type.",
                    {
                      "$ul": [
                        "**fields**: The list of fields that make up this struct. Order is significant, because values of this struct type are represented as lists, where the order of field values matches the order of fields in the StructType. In turn, the order of fields matches the order of columns in a read request, or the order of fields in the `SELECT` clause of a query."
                      ]
                    }
                  ],
                  [
                    "**transaction**: A transaction.",
                    {
                      "$ul": [
                        "**id**: `id` may be used to identify the transaction in subsequent Read, ExecuteSql, Commit, or Rollback calls. Single-use read-only transactions do not have IDs, because single-use transactions do not support multiple requests.",
                        "**readTimestamp**: For snapshot read-only transactions, the read timestamp chosen for the transaction. Not returned by default: see TransactionOptions.ReadOnly.return_read_timestamp. A timestamp in RFC3339 UTC \\\"Zulu\\\" format, accurate to nanoseconds. Example: `\"2014-10-02T15:01:23.045123456Z\"`."
                      ]
                    }
                  ],
                  [
                    "**undeclaredParameters**: `StructType` defines the fields of a STRUCT type.",
                    {
                      "$ul": [
                        "**fields**: The list of fields that make up this struct. Order is significant, because values of this struct type are represented as lists, where the order of field values matches the order of fields in the StructType. In turn, the order of fields matches the order of columns in a read request, or the order of fields in the `SELECT` clause of a query."
                      ]
                    }
                  ]
                ]
              }
            ],
            "**rows**: Each element in `rows` is a row whose format is defined by metadata.row_type. The ith element in each row matches the ith field in metadata.row_type. Elements are encoded based on type as described here.",
            [
              "**stats**: Additional statistics about a ResultSet or PartialResultSet.",
              {
                "$ul": [
                  [
                    "**queryPlan**: Contains an ordered list of nodes appearing in the query plan.",
                    {
                      "$ul": [
                        "**planNodes**: The nodes in the query plan. Plan nodes are returned in pre-order starting with the plan root. Each PlanNode's `id` corresponds to its index in `plan_nodes`.",
                        [
                          "**queryAdvice**: Output of query advisor analysis.",
                          {
                            "$ul": [
                              "**indexAdvice**: Optional. Index Recommendation for a query. This is an optional field and the recommendation will only be available when the recommendation guarantees significant improvement in query performance."
                            ]
                          }
                        ]
                      ]
                    }
                  ],
                  "**queryStats**: Aggregated statistics from the execution of the query. Only present when the query is profiled. For example, a query could return the statistics as follows: { \"rows_returned\": \"3\", \"elapsed_time\": \"1.22 secs\", \"cpu_time\": \"1.19 secs\" }",
                  "**rowCountExact**: Standard DML returns an exact count of rows that were modified.",
                  "**rowCountLowerBound**: Partitioned DML does not offer exactly-once semantics, so it returns a lower bound of the rows modified."
                ]
              }
            ]
          ]
        },
        {
          "$lang": "json",
          "$code": {
            "$encode": "json",
            "$indent": true,
            "$content": {
              "$": "$.body"
            }
          }
        }
      ]
    }
  }
}
