{
  "name": "bigquery_routines_insert",
  "description": "Creates a new routine in the dataset.",
  "parameters": {
    "type": "object",
    "properties": {
      "projectId": {
        "type": "string",
        "description": "Required. Project ID of the new routine"
      },
      "datasetId": {
        "type": "string",
        "description": "Required. Dataset ID of the new routine"
      },
      "$.xgafv": {
        "enum": [
          "1",
          "2"
        ],
        "type": "string",
        "description": "V1 error format."
      },
      "access_token": {
        "type": "string",
        "description": "OAuth access token."
      },
      "alt": {
        "enum": [
          "json",
          "media",
          "proto"
        ],
        "type": "string",
        "description": "Data format for response."
      },
      "callback": {
        "type": "string",
        "description": "JSONP"
      },
      "fields": {
        "type": "string",
        "description": "Selector specifying which fields to include in a partial response."
      },
      "key": {
        "type": "string",
        "description": "API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token."
      },
      "oauth_token": {
        "type": "string",
        "description": "OAuth 2.0 token for the current user."
      },
      "prettyPrint": {
        "type": "boolean",
        "description": "Returns response with indentations and line breaks."
      },
      "quotaUser": {
        "type": "string",
        "description": "Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters."
      },
      "upload_protocol": {
        "type": "string",
        "description": "Upload protocol for media (e.g. \"raw\", \"multipart\")."
      },
      "uploadType": {
        "type": "string",
        "description": "Legacy upload protocol for media (e.g. \"media\", \"multipart\")."
      },
      "body": {
        "$ref": "#/$defs/Routine"
      }
    },
    "required": [
      "projectId",
      "datasetId"
    ],
    "$defs": {
      "Routine": {
        "description": "A user-defined function or a stored procedure.",
        "properties": {
          "arguments": {
            "description": "Optional.",
            "items": {
              "$ref": "#/$defs/Argument"
            },
            "type": "array"
          },
          "creationTime": {
            "description": "Output only. The time when this routine was created, in milliseconds since the epoch.",
            "format": "int64",
            "readOnly": true,
            "type": "string"
          },
          "dataGovernanceType": {
            "description": "Optional. If set to `DATA_MASKING`, the function is validated and made available as a masking function. For more information, see [Create custom masking routines](https://cloud.google.com/bigquery/docs/user-defined-functions#custom-mask).",
            "enum": [
              "DATA_GOVERNANCE_TYPE_UNSPECIFIED",
              "DATA_MASKING"
            ],
            "type": "string"
          },
          "definitionBody": {
            "description": "Required. The body of the routine. For functions, this is the expression in the AS clause. If language=SQL, it is the substring inside (but excluding) the parentheses. For example, for the function created with the following statement: `CREATE FUNCTION JoinLines(x string, y string) as (concat(x, \"\\n\", y))` The definition_body is `concat(x, \"\\n\", y)` (\\n is not replaced with linebreak). If language=JAVASCRIPT, it is the evaluated string in the AS clause. For example, for the function created with the following statement: `CREATE FUNCTION f() RETURNS STRING LANGUAGE js AS 'return \"\\n\";\\n'` The definition_body is `return \"\\n\";\\n` Note that both \\n are replaced with linebreaks.",
            "type": "string"
          },
          "description": {
            "description": "Optional. The description of the routine, if defined.",
            "type": "string"
          },
          "determinismLevel": {
            "description": "Optional. The determinism level of the JavaScript UDF, if defined.",
            "enum": [
              "DETERMINISM_LEVEL_UNSPECIFIED",
              "DETERMINISTIC",
              "NOT_DETERMINISTIC"
            ],
            "type": "string"
          },
          "etag": {
            "description": "Output only. A hash of this resource.",
            "readOnly": true,
            "type": "string"
          },
          "importedLibraries": {
            "description": "Optional. If language = \"JAVASCRIPT\", this field stores the path of the imported JAVASCRIPT libraries.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "language": {
            "description": "Optional. Defaults to \"SQL\" if remote_function_options field is absent, not set otherwise.",
            "enum": [
              "LANGUAGE_UNSPECIFIED",
              "SQL",
              "JAVASCRIPT",
              "PYTHON",
              "JAVA",
              "SCALA"
            ],
            "type": "string"
          },
          "lastModifiedTime": {
            "description": "Output only. The time when this routine was last modified, in milliseconds since the epoch.",
            "format": "int64",
            "readOnly": true,
            "type": "string"
          },
          "remoteFunctionOptions": {
            "$ref": "#/$defs/RemoteFunctionOptions"
          },
          "returnTableType": {
            "$ref": "#/$defs/StandardSqlTableType"
          },
          "returnType": {
            "$ref": "#/$defs/StandardSqlDataType"
          },
          "routineReference": {
            "$ref": "#/$defs/RoutineReference"
          },
          "routineType": {
            "description": "Required. The type of routine.",
            "enum": [
              "ROUTINE_TYPE_UNSPECIFIED",
              "SCALAR_FUNCTION",
              "PROCEDURE",
              "TABLE_VALUED_FUNCTION",
              "AGGREGATE_FUNCTION"
            ],
            "type": "string"
          },
          "securityMode": {
            "description": "Optional. The security mode of the routine, if defined. If not defined, the security mode is automatically determined from the routine's configuration.",
            "enum": [
              "SECURITY_MODE_UNSPECIFIED",
              "DEFINER",
              "INVOKER"
            ],
            "type": "string"
          },
          "sparkOptions": {
            "$ref": "#/$defs/SparkOptions"
          },
          "strictMode": {
            "description": "Optional. Use this option to catch many common errors. Error checking is not exhaustive, and successfully creating a procedure doesn't guarantee that the procedure will successfully execute at runtime. If `strictMode` is set to `TRUE`, the procedure body is further checked for errors such as non-existent tables or columns. The `CREATE PROCEDURE` statement fails if the body fails any of these checks. If `strictMode` is set to `FALSE`, the procedure body is checked only for syntax. For procedures that invoke themselves recursively, specify `strictMode=FALSE` to avoid non-existent procedure errors during validation. Default value is `TRUE`.",
            "type": "boolean"
          }
        },
        "type": "object"
      },
      "Argument": {
        "description": "Input/output argument of a function or a stored procedure.",
        "properties": {
          "argumentKind": {
            "description": "Optional. Defaults to FIXED_TYPE.",
            "enum": [
              "ARGUMENT_KIND_UNSPECIFIED",
              "FIXED_TYPE",
              "ANY_TYPE"
            ],
            "type": "string"
          },
          "dataType": {
            "$ref": "#/$defs/StandardSqlDataType"
          },
          "isAggregate": {
            "description": "Optional. Whether the argument is an aggregate function parameter. Must be Unset for routine types other than AGGREGATE_FUNCTION. For AGGREGATE_FUNCTION, if set to false, it is equivalent to adding \"NOT AGGREGATE\" clause in DDL; Otherwise, it is equivalent to omitting \"NOT AGGREGATE\" clause in DDL.",
            "type": "boolean"
          },
          "mode": {
            "description": "Optional. Specifies whether the argument is input or output. Can be set for procedures only.",
            "enum": [
              "MODE_UNSPECIFIED",
              "IN",
              "OUT",
              "INOUT"
            ],
            "type": "string"
          },
          "name": {
            "description": "Optional. The name of this argument. Can be absent for function return argument.",
            "type": "string"
          }
        },
        "type": "object"
      },
      "StandardSqlDataType": {
        "description": "The data type of a variable such as a function argument. Examples include: * INT64: `{\"typeKind\": \"INT64\"}` * ARRAY: { \"typeKind\": \"ARRAY\", \"arrayElementType\": {\"typeKind\": \"STRING\"} } * STRUCT>: { \"typeKind\": \"STRUCT\", \"structType\": { \"fields\": [ { \"name\": \"x\", \"type\": {\"typeKind\": \"STRING\"} }, { \"name\": \"y\", \"type\": { \"typeKind\": \"ARRAY\", \"arrayElementType\": {\"typeKind\": \"DATE\"} } } ] } }",
        "properties": {
          "arrayElementType": {
            "$ref": "#/$defs/StandardSqlDataType"
          },
          "rangeElementType": {
            "$ref": "#/$defs/StandardSqlDataType"
          },
          "structType": {
            "$ref": "#/$defs/StandardSqlStructType"
          },
          "typeKind": {
            "description": "Required. The top level type of this field. Can be any GoogleSQL data type (e.g., \"INT64\", \"DATE\", \"ARRAY\").",
            "enum": [
              "TYPE_KIND_UNSPECIFIED",
              "INT64",
              "BOOL",
              "FLOAT64",
              "STRING",
              "BYTES",
              "TIMESTAMP",
              "DATE",
              "TIME",
              "DATETIME",
              "INTERVAL",
              "GEOGRAPHY",
              "NUMERIC",
              "BIGNUMERIC",
              "JSON",
              "ARRAY",
              "STRUCT",
              "RANGE"
            ],
            "type": "string"
          }
        },
        "type": "object"
      },
      "StandardSqlStructType": {
        "description": "The representation of a SQL STRUCT type.",
        "properties": {
          "fields": {
            "description": "Fields within the struct.",
            "items": {
              "$ref": "#/$defs/StandardSqlField"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "StandardSqlField": {
        "description": "A field or a column.",
        "properties": {
          "name": {
            "description": "Optional. The name of this field. Can be absent for struct fields.",
            "type": "string"
          },
          "type": {
            "$ref": "#/$defs/StandardSqlDataType"
          }
        },
        "type": "object"
      },
      "RemoteFunctionOptions": {
        "description": "Options for a remote user-defined function.",
        "properties": {
          "connection": {
            "description": "Fully qualified name of the user-provided connection object which holds the authentication information to send requests to the remote service. Format: ```\"projects/{projectId}/locations/{locationId}/connections/{connectionId}\"```",
            "type": "string"
          },
          "endpoint": {
            "description": "Endpoint of the user-provided remote service, e.g. ```https://us-east1-my_gcf_project.cloudfunctions.net/remote_add```",
            "type": "string"
          },
          "maxBatchingRows": {
            "description": "Max number of rows in each batch sent to the remote service. If absent or if 0, BigQuery dynamically decides the number of rows in a batch.",
            "format": "int64",
            "type": "string"
          },
          "userDefinedContext": {
            "additionalProperties": {
              "type": "string"
            },
            "description": "User-defined context as a set of key/value pairs, which will be sent as function invocation context together with batched arguments in the requests to the remote service. The total number of bytes of keys and values must be less than 8KB.",
            "type": "object"
          }
        },
        "type": "object"
      },
      "StandardSqlTableType": {
        "description": "A table type",
        "properties": {
          "columns": {
            "description": "The columns in this table type",
            "items": {
              "$ref": "#/$defs/StandardSqlField"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "RoutineReference": {
        "description": "Id path of a routine.",
        "properties": {
          "datasetId": {
            "description": "Required. The ID of the dataset containing this routine.",
            "type": "string"
          },
          "projectId": {
            "description": "Required. The ID of the project containing this routine.",
            "type": "string"
          },
          "routineId": {
            "description": "Required. The ID of the routine. The ID must contain only letters (a-z, A-Z), numbers (0-9), or underscores (_). The maximum length is 256 characters.",
            "type": "string"
          }
        },
        "type": "object"
      },
      "SparkOptions": {
        "description": "Options for a user-defined Spark routine.",
        "properties": {
          "archiveUris": {
            "description": "Archive files to be extracted into the working directory of each executor. For more information about Apache Spark, see [Apache Spark](https://spark.apache.org/docs/latest/index.html).",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "connection": {
            "description": "Fully qualified name of the user-provided Spark connection object. Format: ```\"projects/{project_id}/locations/{location_id}/connections/{connection_id}\"```",
            "type": "string"
          },
          "containerImage": {
            "description": "Custom container image for the runtime environment.",
            "type": "string"
          },
          "fileUris": {
            "description": "Files to be placed in the working directory of each executor. For more information about Apache Spark, see [Apache Spark](https://spark.apache.org/docs/latest/index.html).",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "jarUris": {
            "description": "JARs to include on the driver and executor CLASSPATH. For more information about Apache Spark, see [Apache Spark](https://spark.apache.org/docs/latest/index.html).",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "mainClass": {
            "description": "The fully qualified name of a class in jar_uris, for example, com.example.wordcount. Exactly one of main_class and main_jar_uri field should be set for Java/Scala language type.",
            "type": "string"
          },
          "mainFileUri": {
            "description": "The main file/jar URI of the Spark application. Exactly one of the definition_body field and the main_file_uri field must be set for Python. Exactly one of main_class and main_file_uri field should be set for Java/Scala language type.",
            "type": "string"
          },
          "properties": {
            "additionalProperties": {
              "type": "string"
            },
            "description": "Configuration properties as a set of key/value pairs, which will be passed on to the Spark application. For more information, see [Apache Spark](https://spark.apache.org/docs/latest/index.html) and the [procedure option list](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#procedure_option_list).",
            "type": "object"
          },
          "pyFileUris": {
            "description": "Python files to be placed on the PYTHONPATH for PySpark application. Supported file types: `.py`, `.egg`, and `.zip`. For more information about Apache Spark, see [Apache Spark](https://spark.apache.org/docs/latest/index.html).",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "runtimeVersion": {
            "description": "Runtime version. If not specified, the default runtime version is used.",
            "type": "string"
          }
        },
        "type": "object"
      }
    }
  },
  "handler": "http",
  "request": {
    "method": "POST",
    "url": {
      "$uri": "https://bigquery.googleapis.com/bigquery/v2/projects/{projectId}/datasets/{datasetId}/routines{?$.xgafv,access_token,alt,callback,fields,key,oauth_token,prettyPrint,quotaUser,upload_protocol,uploadType}"
    },
    "body": {
      "$": "body",
      "encode": "json"
    }
  },
  "responses": {
    "200": {
      "$encode": "markdown",
      "$block": [
        {
          "$h1": "Object"
        },
        "A user-defined function or a stored procedure.",
        "**Key properties:**",
        {
          "$ul": [
            "**arguments**: Optional.",
            "**creationTime**: Output only. The time when this routine was created, in milliseconds since the epoch.",
            "**dataGovernanceType**: Optional. If set to `DATA_MASKING`, the function is validated and made available as a masking function. For more information, see [Create custom masking routines](https://cloud.google.com/bigquery/docs/user-defined-functions#custom-mask).",
            "**definitionBody**: Required. The body of the routine. For functions, this is the expression in the AS clause. If language=SQL, it is the substring inside (but excluding) the parentheses. For example, for the function created with the following statement: `CREATE FUNCTION JoinLines(x string, y string) as (concat(x, \"\\n\", y))` The definition_body is `concat(x, \"\\n\", y)` (\\n is not replaced with linebreak). If language=JAVASCRIPT, it is the evaluated string in the AS clause. For example, for the function created with the following statement: `CREATE FUNCTION f() RETURNS STRING LANGUAGE js AS 'return \"\\n\";\\n'` The definition_body is `return \"\\n\";\\n` Note that both \\n are replaced with linebreaks.",
            "**description**: Optional. The description of the routine, if defined.",
            "**determinismLevel**: Optional. The determinism level of the JavaScript UDF, if defined.",
            "**etag**: Output only. A hash of this resource.",
            "**importedLibraries**: Optional. If language = \"JAVASCRIPT\", this field stores the path of the imported JAVASCRIPT libraries.",
            "**language**: Optional. Defaults to \"SQL\" if remote_function_options field is absent, not set otherwise.",
            "**lastModifiedTime**: Output only. The time when this routine was last modified, in milliseconds since the epoch.",
            [
              "**remoteFunctionOptions**: Options for a remote user-defined function.",
              {
                "$ul": [
                  "**connection**: Fully qualified name of the user-provided connection object which holds the authentication information to send requests to the remote service. Format: ```\"projects/{projectId}/locations/{locationId}/connections/{connectionId}\"```",
                  "**endpoint**: Endpoint of the user-provided remote service, e.g. ```https://us-east1-my_gcf_project.cloudfunctions.net/remote_add```",
                  "**maxBatchingRows**: Max number of rows in each batch sent to the remote service. If absent or if 0, BigQuery dynamically decides the number of rows in a batch.",
                  "**userDefinedContext**: User-defined context as a set of key/value pairs, which will be sent as function invocation context together with batched arguments in the requests to the remote service. The total number of bytes of keys and values must be less than 8KB."
                ]
              }
            ],
            [
              "**returnTableType**: A table type",
              {
                "$ul": [
                  "**columns**: The columns in this table type"
                ]
              }
            ],
            [
              "**returnType**: The data type of a variable such as a function argument. Examples include: * INT64: `{\"typeKind\": \"INT64\"}` * ARRAY: { \"typeKind\": \"ARRAY\", \"arrayElementType\": {\"typeKind\": \"STRING\"} } * STRUCT>: { \"typeKind\": \"STRUCT\", \"structType\": { \"fields\": [ { \"name\": \"x\", \"type\": {\"typeKind\": \"STRING\"} }, { \"name\": \"y\", \"type\": { \"typeKind\": \"ARRAY\", \"arrayElementType\": {\"typeKind\": \"DATE\"} } } ] } }",
              {
                "$ul": [
                  "**arrayElementType**",
                  "**rangeElementType**",
                  [
                    "**structType**: The representation of a SQL STRUCT type.",
                    {
                      "$ul": [
                        "**fields**: Fields within the struct."
                      ]
                    }
                  ],
                  "**typeKind**: Required. The top level type of this field. Can be any GoogleSQL data type (e.g., \"INT64\", \"DATE\", \"ARRAY\")."
                ]
              }
            ],
            [
              "**routineReference**: Id path of a routine.",
              {
                "$ul": [
                  "**datasetId**: Required. The ID of the dataset containing this routine.",
                  "**projectId**: Required. The ID of the project containing this routine.",
                  "**routineId**: Required. The ID of the routine. The ID must contain only letters (a-z, A-Z), numbers (0-9), or underscores (_). The maximum length is 256 characters."
                ]
              }
            ],
            "**routineType**: Required. The type of routine.",
            "**securityMode**: Optional. The security mode of the routine, if defined. If not defined, the security mode is automatically determined from the routine's configuration.",
            [
              "**sparkOptions**: Options for a user-defined Spark routine.",
              {
                "$ul": [
                  "**archiveUris**: Archive files to be extracted into the working directory of each executor. For more information about Apache Spark, see [Apache Spark](https://spark.apache.org/docs/latest/index.html).",
                  "**connection**: Fully qualified name of the user-provided Spark connection object. Format: ```\"projects/{project_id}/locations/{location_id}/connections/{connection_id}\"```",
                  "**containerImage**: Custom container image for the runtime environment.",
                  "**fileUris**: Files to be placed in the working directory of each executor. For more information about Apache Spark, see [Apache Spark](https://spark.apache.org/docs/latest/index.html).",
                  "**jarUris**: JARs to include on the driver and executor CLASSPATH. For more information about Apache Spark, see [Apache Spark](https://spark.apache.org/docs/latest/index.html).",
                  "**mainClass**: The fully qualified name of a class in jar_uris, for example, com.example.wordcount. Exactly one of main_class and main_jar_uri field should be set for Java/Scala language type.",
                  "**mainFileUri**: The main file/jar URI of the Spark application. Exactly one of the definition_body field and the main_file_uri field must be set for Python. Exactly one of main_class and main_file_uri field should be set for Java/Scala language type.",
                  "**properties**: Configuration properties as a set of key/value pairs, which will be passed on to the Spark application. For more information, see [Apache Spark](https://spark.apache.org/docs/latest/index.html) and the [procedure option list](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#procedure_option_list).",
                  "**pyFileUris**: Python files to be placed on the PYTHONPATH for PySpark application. Supported file types: `.py`, `.egg`, and `.zip`. For more information about Apache Spark, see [Apache Spark](https://spark.apache.org/docs/latest/index.html).",
                  "**runtimeVersion**: Runtime version. If not specified, the default runtime version is used."
                ]
              }
            ],
            "**strictMode**: Optional. Use this option to catch many common errors. Error checking is not exhaustive, and successfully creating a procedure doesn't guarantee that the procedure will successfully execute at runtime. If `strictMode` is set to `TRUE`, the procedure body is further checked for errors such as non-existent tables or columns. The `CREATE PROCEDURE` statement fails if the body fails any of these checks. If `strictMode` is set to `FALSE`, the procedure body is checked only for syntax. For procedures that invoke themselves recursively, specify `strictMode=FALSE` to avoid non-existent procedure errors during validation. Default value is `TRUE`."
          ]
        },
        {
          "$lang": "json",
          "$code": {
            "$encode": "json",
            "$indent": true,
            "$content": {
              "$": "$.body"
            }
          }
        }
      ]
    }
  }
}
