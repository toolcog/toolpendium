{
  "name": "vision_projects_locations_images_asyncBatchAnnotate",
  "description": "Run asynchronous image detection and annotation for a list of images. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateImagesResponse` (results). This service will write image annotation outputs to json files in customer GCS bucket, each json file containing BatchAnnotateImagesResponse proto.",
  "parameters": {
    "type": "object",
    "properties": {
      "parent": {
        "type": "string",
        "description": "Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`."
      },
      "$.xgafv": {
        "enum": [
          "1",
          "2"
        ],
        "type": "string",
        "description": "V1 error format."
      },
      "access_token": {
        "type": "string",
        "description": "OAuth access token."
      },
      "alt": {
        "enum": [
          "json",
          "media",
          "proto"
        ],
        "type": "string",
        "description": "Data format for response."
      },
      "callback": {
        "type": "string",
        "description": "JSONP"
      },
      "fields": {
        "type": "string",
        "description": "Selector specifying which fields to include in a partial response."
      },
      "key": {
        "type": "string",
        "description": "API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token."
      },
      "oauth_token": {
        "type": "string",
        "description": "OAuth 2.0 token for the current user."
      },
      "prettyPrint": {
        "type": "boolean",
        "description": "Returns response with indentations and line breaks."
      },
      "quotaUser": {
        "type": "string",
        "description": "Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters."
      },
      "upload_protocol": {
        "type": "string",
        "description": "Upload protocol for media (e.g. \"raw\", \"multipart\")."
      },
      "uploadType": {
        "type": "string",
        "description": "Legacy upload protocol for media (e.g. \"media\", \"multipart\")."
      },
      "body": {
        "$ref": "#/$defs/GoogleCloudVisionV1p2beta1AsyncBatchAnnotateImagesRequest"
      }
    },
    "required": [
      "parent"
    ],
    "$defs": {
      "GoogleCloudVisionV1p2beta1AsyncBatchAnnotateImagesRequest": {
        "description": "Request for async image annotation for a list of images.",
        "properties": {
          "labels": {
            "additionalProperties": {
              "type": "string"
            },
            "description": "Optional. The labels with user-defined metadata for the request. Label keys and values can be no longer than 63 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. Label values are optional. Label keys must start with a letter.",
            "type": "object"
          },
          "outputConfig": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1OutputConfig"
          },
          "parent": {
            "description": "Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`.",
            "type": "string"
          },
          "requests": {
            "description": "Required. Individual image annotation requests for this batch.",
            "items": {
              "$ref": "#/$defs/GoogleCloudVisionV1p2beta1AnnotateImageRequest"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1OutputConfig": {
        "description": "The desired output location and metadata.",
        "properties": {
          "batchSize": {
            "description": "The max number of response protos to put into each output JSON file on Google Cloud Storage. The valid range is [1, 100]. If not specified, the default value is 20. For example, for one pdf file with 100 pages, 100 response protos will be generated. If `batch_size` = 20, then 5 json files each containing 20 response protos will be written under the prefix `gcs_destination`.`uri`. Currently, batch_size only applies to GcsDestination, with potential future support for other output configurations.",
            "format": "int32",
            "type": "integer"
          },
          "gcsDestination": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1GcsDestination"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1GcsDestination": {
        "description": "The Google Cloud Storage location where the output will be written to.",
        "properties": {
          "uri": {
            "description": "Google Cloud Storage URI prefix where the results will be stored. Results will be in JSON format and preceded by its corresponding input URI prefix. This field can either represent a gcs file prefix or gcs directory. In either case, the uri should be unique because in order to get all of the output files, you will need to do a wildcard gcs search on the uri prefix you provide. Examples: * File Prefix: gs://bucket-name/here/filenameprefix The output files will be created in gs://bucket-name/here/ and the names of the output files will begin with \"filenameprefix\". * Directory Prefix: gs://bucket-name/some/location/ The output files will be created in gs://bucket-name/some/location/ and the names of the output files could be anything because there was no filename prefix specified. If multiple outputs, each response is still AnnotateFileResponse, each of which contains some subset of the full list of AnnotateImageResponse. Multiple outputs can happen if, for example, the output JSON is too large and overflows into multiple sharded files.",
            "type": "string"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1AnnotateImageRequest": {
        "description": "Request for performing Google Cloud Vision API tasks over a user-provided image, with user-requested features, and with context information.",
        "properties": {
          "features": {
            "description": "Requested features.",
            "items": {
              "$ref": "#/$defs/GoogleCloudVisionV1p2beta1Feature"
            },
            "type": "array"
          },
          "image": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1Image"
          },
          "imageContext": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1ImageContext"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1Feature": {
        "description": "The type of Google Cloud Vision API detection to perform, and the maximum number of results to return for that type. Multiple `Feature` objects can be specified in the `features` list.",
        "properties": {
          "maxResults": {
            "description": "Maximum number of results of this type. Does not apply to `TEXT_DETECTION`, `DOCUMENT_TEXT_DETECTION`, or `CROP_HINTS`.",
            "format": "int32",
            "type": "integer"
          },
          "model": {
            "description": "Model to use for the feature. Supported values: \"builtin/stable\" (the default if unset) and \"builtin/latest\". `DOCUMENT_TEXT_DETECTION` and `TEXT_DETECTION` also support \"builtin/weekly\" for the bleeding edge release updated weekly.",
            "type": "string"
          },
          "type": {
            "description": "The feature type.",
            "enum": [
              "TYPE_UNSPECIFIED",
              "FACE_DETECTION",
              "LANDMARK_DETECTION",
              "LOGO_DETECTION",
              "LABEL_DETECTION",
              "TEXT_DETECTION",
              "DOCUMENT_TEXT_DETECTION",
              "SAFE_SEARCH_DETECTION",
              "IMAGE_PROPERTIES",
              "CROP_HINTS",
              "WEB_DETECTION",
              "PRODUCT_SEARCH",
              "OBJECT_LOCALIZATION"
            ],
            "type": "string"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1Image": {
        "description": "Client image to perform Google Cloud Vision API tasks over.",
        "properties": {
          "content": {
            "description": "Image content, represented as a stream of bytes. Note: As with all `bytes` fields, protobuffers use a pure binary representation, whereas JSON representations use base64. Currently, this field only works for BatchAnnotateImages requests. It does not work for AsyncBatchAnnotateImages requests.",
            "format": "byte",
            "type": "string"
          },
          "source": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1ImageSource"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1ImageSource": {
        "description": "External image source (Google Cloud Storage or web URL image location).",
        "properties": {
          "gcsImageUri": {
            "description": "**Use `image_uri` instead.** The Google Cloud Storage URI of the form `gs://bucket_name/object_name`. Object versioning is not supported. See [Google Cloud Storage Request URIs](https://cloud.google.com/storage/docs/reference-uris) for more info.",
            "type": "string"
          },
          "imageUri": {
            "description": "The URI of the source image. Can be either: 1. A Google Cloud Storage URI of the form `gs://bucket_name/object_name`. Object versioning is not supported. See [Google Cloud Storage Request URIs](https://cloud.google.com/storage/docs/reference-uris) for more info. 2. A publicly-accessible image HTTP/HTTPS URL. When fetching images from HTTP/HTTPS URLs, Google cannot guarantee that the request will be completed. Your request may fail if the specified host denies the request (e.g. due to request throttling or DOS prevention), or if Google throttles requests to the site for abuse prevention. You should not depend on externally-hosted images for production applications. When both `gcs_image_uri` and `image_uri` are specified, `image_uri` takes precedence.",
            "type": "string"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1ImageContext": {
        "description": "Image context and/or feature-specific parameters.",
        "properties": {
          "cropHintsParams": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1CropHintsParams"
          },
          "languageHints": {
            "description": "List of languages to use for TEXT_DETECTION. In most cases, an empty value yields the best results since it enables automatic language detection. For languages based on the Latin alphabet, setting `language_hints` is not needed. In rare cases, when the language of the text in the image is known, setting a hint will help get better results (although it will be a significant hindrance if the hint is wrong). Text detection returns an error if one or more of the specified languages is not one of the [supported languages](https://cloud.google.com/vision/docs/languages).",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "latLongRect": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1LatLongRect"
          },
          "productSearchParams": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1ProductSearchParams"
          },
          "textDetectionParams": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1TextDetectionParams"
          },
          "webDetectionParams": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1WebDetectionParams"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1CropHintsParams": {
        "description": "Parameters for crop hints annotation request.",
        "properties": {
          "aspectRatios": {
            "description": "Aspect ratios in floats, representing the ratio of the width to the height of the image. For example, if the desired aspect ratio is 4/3, the corresponding float value should be 1.33333. If not specified, the best possible crop is returned. The number of provided aspect ratios is limited to a maximum of 16; any aspect ratios provided after the 16th are ignored.",
            "items": {
              "format": "float",
              "type": "number"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1LatLongRect": {
        "description": "Rectangle determined by min and max `LatLng` pairs.",
        "properties": {
          "maxLatLng": {
            "$ref": "#/$defs/LatLng"
          },
          "minLatLng": {
            "$ref": "#/$defs/LatLng"
          }
        },
        "type": "object"
      },
      "LatLng": {
        "description": "An object that represents a latitude/longitude pair. This is expressed as a pair of doubles to represent degrees latitude and degrees longitude. Unless specified otherwise, this object must conform to the WGS84 standard. Values must be within normalized ranges.",
        "properties": {
          "latitude": {
            "description": "The latitude in degrees. It must be in the range [-90.0, +90.0].",
            "format": "double",
            "type": "number"
          },
          "longitude": {
            "description": "The longitude in degrees. It must be in the range [-180.0, +180.0].",
            "format": "double",
            "type": "number"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1ProductSearchParams": {
        "description": "Parameters for a product search request.",
        "properties": {
          "boundingPoly": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1BoundingPoly"
          },
          "filter": {
            "description": "The filtering expression. This can be used to restrict search results based on Product labels. We currently support an AND of OR of key-value expressions, where each expression within an OR must have the same key. An '=' should be used to connect the key and value. For example, \"(color = red OR color = blue) AND brand = Google\" is acceptable, but \"(color = red OR brand = Google)\" is not acceptable. \"color: red\" is not acceptable because it uses a ':' instead of an '='.",
            "type": "string"
          },
          "productCategories": {
            "description": "The list of product categories to search in. Currently, we only consider the first category, and either \"homegoods-v2\", \"apparel-v2\", \"toys-v2\", \"packagedgoods-v1\", or \"general-v1\" should be specified. The legacy categories \"homegoods\", \"apparel\", and \"toys\" are still supported but will be deprecated. For new products, please use \"homegoods-v2\", \"apparel-v2\", or \"toys-v2\" for better product search accuracy. It is recommended to migrate existing products to these categories as well.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "productSet": {
            "description": "The resource name of a ProductSet to be searched for similar images. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`.",
            "type": "string"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1BoundingPoly": {
        "description": "A bounding polygon for the detected image annotation.",
        "properties": {
          "normalizedVertices": {
            "description": "The bounding polygon normalized vertices.",
            "items": {
              "$ref": "#/$defs/GoogleCloudVisionV1p2beta1NormalizedVertex"
            },
            "type": "array"
          },
          "vertices": {
            "description": "The bounding polygon vertices.",
            "items": {
              "$ref": "#/$defs/GoogleCloudVisionV1p2beta1Vertex"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1NormalizedVertex": {
        "description": "A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1.",
        "properties": {
          "x": {
            "description": "X coordinate.",
            "format": "float",
            "type": "number"
          },
          "y": {
            "description": "Y coordinate.",
            "format": "float",
            "type": "number"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1Vertex": {
        "description": "A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image.",
        "properties": {
          "x": {
            "description": "X coordinate.",
            "format": "int32",
            "type": "integer"
          },
          "y": {
            "description": "Y coordinate.",
            "format": "int32",
            "type": "integer"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1TextDetectionParams": {
        "description": "Parameters for text detections. This is used to control TEXT_DETECTION and DOCUMENT_TEXT_DETECTION features.",
        "properties": {
          "advancedOcrOptions": {
            "description": "A list of advanced OCR options to further fine-tune OCR behavior. Current valid values are: - `legacy_layout`: a heuristics layout detection algorithm, which serves as an alternative to the current ML-based layout detection algorithm. Customers can choose the best suitable layout algorithm based on their situation.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "enableTextDetectionConfidenceScore": {
            "description": "By default, Cloud Vision API only includes confidence score for DOCUMENT_TEXT_DETECTION result. Set the flag to true to include confidence score for TEXT_DETECTION as well.",
            "type": "boolean"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1WebDetectionParams": {
        "description": "Parameters for web detection request.",
        "properties": {
          "includeGeoResults": {
            "deprecated": true,
            "description": "This field has no effect on results.",
            "type": "boolean"
          }
        },
        "type": "object"
      }
    }
  },
  "handler": "http",
  "request": {
    "method": "POST",
    "url": {
      "$uri": "https://vision.googleapis.com//v1p2beta1/{parent}/images:asyncBatchAnnotate{?$.xgafv,access_token,alt,callback,fields,key,oauth_token,prettyPrint,quotaUser,upload_protocol,uploadType}"
    },
    "body": {
      "$": "body",
      "encode": "json"
    }
  },
  "responses": {
    "200": {
      "$encode": "markdown",
      "$block": [
        {
          "$h1": "Object"
        },
        "This resource represents a long-running operation that is the result of a network API call.",
        "**Key properties:**",
        {
          "$ul": [
            "**done**: If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.",
            [
              "**error**: The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).",
              {
                "$ul": [
                  "**code**: The status code, which should be an enum value of google.rpc.Code.",
                  "**details**: A list of messages that carry the error details. There is a common set of message types for APIs to use.",
                  "**message**: A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                ]
              }
            ],
            "**metadata**: Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
            "**name**: The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.",
            "**response**: The normal, successful response of the operation. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`."
          ]
        },
        {
          "$lang": "json",
          "$code": {
            "$encode": "json",
            "$indent": true,
            "$content": {
              "$": "$.body"
            }
          }
        }
      ]
    }
  }
}
