{
  "name": "vision_files_annotate",
  "description": "Service that performs image detection and annotation for a batch of files. Now only \"application/pdf\", \"image/tiff\" and \"image/gif\" are supported. This service will extract at most 5 (customers can specify which 5 in AnnotateFileRequest.pages) frames (gif) or pages (pdf or tiff) from each file provided and perform detection and annotation for each image extracted.",
  "parameters": {
    "type": "object",
    "properties": {
      "$.xgafv": {
        "enum": [
          "1",
          "2"
        ],
        "type": "string",
        "description": "V1 error format."
      },
      "access_token": {
        "type": "string",
        "description": "OAuth access token."
      },
      "alt": {
        "enum": [
          "json",
          "media",
          "proto"
        ],
        "type": "string",
        "description": "Data format for response."
      },
      "callback": {
        "type": "string",
        "description": "JSONP"
      },
      "fields": {
        "type": "string",
        "description": "Selector specifying which fields to include in a partial response."
      },
      "key": {
        "type": "string",
        "description": "API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token."
      },
      "oauth_token": {
        "type": "string",
        "description": "OAuth 2.0 token for the current user."
      },
      "prettyPrint": {
        "type": "boolean",
        "description": "Returns response with indentations and line breaks."
      },
      "quotaUser": {
        "type": "string",
        "description": "Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters."
      },
      "upload_protocol": {
        "type": "string",
        "description": "Upload protocol for media (e.g. \"raw\", \"multipart\")."
      },
      "uploadType": {
        "type": "string",
        "description": "Legacy upload protocol for media (e.g. \"media\", \"multipart\")."
      },
      "body": {
        "$ref": "#/$defs/GoogleCloudVisionV1p2beta1BatchAnnotateFilesRequest"
      }
    },
    "$defs": {
      "GoogleCloudVisionV1p2beta1BatchAnnotateFilesRequest": {
        "description": "A list of requests to annotate files using the BatchAnnotateFiles API.",
        "properties": {
          "labels": {
            "additionalProperties": {
              "type": "string"
            },
            "description": "Optional. The labels with user-defined metadata for the request. Label keys and values can be no longer than 63 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. Label values are optional. Label keys must start with a letter.",
            "type": "object"
          },
          "parent": {
            "description": "Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`.",
            "type": "string"
          },
          "requests": {
            "description": "Required. The list of file annotation requests. Right now we support only one AnnotateFileRequest in BatchAnnotateFilesRequest.",
            "items": {
              "$ref": "#/$defs/GoogleCloudVisionV1p2beta1AnnotateFileRequest"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1AnnotateFileRequest": {
        "description": "A request to annotate one single file, e.g. a PDF, TIFF or GIF file.",
        "properties": {
          "features": {
            "description": "Required. Requested features.",
            "items": {
              "$ref": "#/$defs/GoogleCloudVisionV1p2beta1Feature"
            },
            "type": "array"
          },
          "imageContext": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1ImageContext"
          },
          "inputConfig": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1InputConfig"
          },
          "pages": {
            "description": "Pages of the file to perform image annotation. Pages starts from 1, we assume the first page of the file is page 1. At most 5 pages are supported per request. Pages can be negative. Page 1 means the first page. Page 2 means the second page. Page -1 means the last page. Page -2 means the second to the last page. If the file is GIF instead of PDF or TIFF, page refers to GIF frames. If this field is empty, by default the service performs image annotation for the first 5 pages of the file.",
            "items": {
              "format": "int32",
              "type": "integer"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1Feature": {
        "description": "The type of Google Cloud Vision API detection to perform, and the maximum number of results to return for that type. Multiple `Feature` objects can be specified in the `features` list.",
        "properties": {
          "maxResults": {
            "description": "Maximum number of results of this type. Does not apply to `TEXT_DETECTION`, `DOCUMENT_TEXT_DETECTION`, or `CROP_HINTS`.",
            "format": "int32",
            "type": "integer"
          },
          "model": {
            "description": "Model to use for the feature. Supported values: \"builtin/stable\" (the default if unset) and \"builtin/latest\". `DOCUMENT_TEXT_DETECTION` and `TEXT_DETECTION` also support \"builtin/weekly\" for the bleeding edge release updated weekly.",
            "type": "string"
          },
          "type": {
            "description": "The feature type.",
            "enum": [
              "TYPE_UNSPECIFIED",
              "FACE_DETECTION",
              "LANDMARK_DETECTION",
              "LOGO_DETECTION",
              "LABEL_DETECTION",
              "TEXT_DETECTION",
              "DOCUMENT_TEXT_DETECTION",
              "SAFE_SEARCH_DETECTION",
              "IMAGE_PROPERTIES",
              "CROP_HINTS",
              "WEB_DETECTION",
              "PRODUCT_SEARCH",
              "OBJECT_LOCALIZATION"
            ],
            "type": "string"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1ImageContext": {
        "description": "Image context and/or feature-specific parameters.",
        "properties": {
          "cropHintsParams": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1CropHintsParams"
          },
          "languageHints": {
            "description": "List of languages to use for TEXT_DETECTION. In most cases, an empty value yields the best results since it enables automatic language detection. For languages based on the Latin alphabet, setting `language_hints` is not needed. In rare cases, when the language of the text in the image is known, setting a hint will help get better results (although it will be a significant hindrance if the hint is wrong). Text detection returns an error if one or more of the specified languages is not one of the [supported languages](https://cloud.google.com/vision/docs/languages).",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "latLongRect": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1LatLongRect"
          },
          "productSearchParams": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1ProductSearchParams"
          },
          "textDetectionParams": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1TextDetectionParams"
          },
          "webDetectionParams": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1WebDetectionParams"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1CropHintsParams": {
        "description": "Parameters for crop hints annotation request.",
        "properties": {
          "aspectRatios": {
            "description": "Aspect ratios in floats, representing the ratio of the width to the height of the image. For example, if the desired aspect ratio is 4/3, the corresponding float value should be 1.33333. If not specified, the best possible crop is returned. The number of provided aspect ratios is limited to a maximum of 16; any aspect ratios provided after the 16th are ignored.",
            "items": {
              "format": "float",
              "type": "number"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1LatLongRect": {
        "description": "Rectangle determined by min and max `LatLng` pairs.",
        "properties": {
          "maxLatLng": {
            "$ref": "#/$defs/LatLng"
          },
          "minLatLng": {
            "$ref": "#/$defs/LatLng"
          }
        },
        "type": "object"
      },
      "LatLng": {
        "description": "An object that represents a latitude/longitude pair. This is expressed as a pair of doubles to represent degrees latitude and degrees longitude. Unless specified otherwise, this object must conform to the WGS84 standard. Values must be within normalized ranges.",
        "properties": {
          "latitude": {
            "description": "The latitude in degrees. It must be in the range [-90.0, +90.0].",
            "format": "double",
            "type": "number"
          },
          "longitude": {
            "description": "The longitude in degrees. It must be in the range [-180.0, +180.0].",
            "format": "double",
            "type": "number"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1ProductSearchParams": {
        "description": "Parameters for a product search request.",
        "properties": {
          "boundingPoly": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1BoundingPoly"
          },
          "filter": {
            "description": "The filtering expression. This can be used to restrict search results based on Product labels. We currently support an AND of OR of key-value expressions, where each expression within an OR must have the same key. An '=' should be used to connect the key and value. For example, \"(color = red OR color = blue) AND brand = Google\" is acceptable, but \"(color = red OR brand = Google)\" is not acceptable. \"color: red\" is not acceptable because it uses a ':' instead of an '='.",
            "type": "string"
          },
          "productCategories": {
            "description": "The list of product categories to search in. Currently, we only consider the first category, and either \"homegoods-v2\", \"apparel-v2\", \"toys-v2\", \"packagedgoods-v1\", or \"general-v1\" should be specified. The legacy categories \"homegoods\", \"apparel\", and \"toys\" are still supported but will be deprecated. For new products, please use \"homegoods-v2\", \"apparel-v2\", or \"toys-v2\" for better product search accuracy. It is recommended to migrate existing products to these categories as well.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "productSet": {
            "description": "The resource name of a ProductSet to be searched for similar images. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`.",
            "type": "string"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1BoundingPoly": {
        "description": "A bounding polygon for the detected image annotation.",
        "properties": {
          "normalizedVertices": {
            "description": "The bounding polygon normalized vertices.",
            "items": {
              "$ref": "#/$defs/GoogleCloudVisionV1p2beta1NormalizedVertex"
            },
            "type": "array"
          },
          "vertices": {
            "description": "The bounding polygon vertices.",
            "items": {
              "$ref": "#/$defs/GoogleCloudVisionV1p2beta1Vertex"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1NormalizedVertex": {
        "description": "A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1.",
        "properties": {
          "x": {
            "description": "X coordinate.",
            "format": "float",
            "type": "number"
          },
          "y": {
            "description": "Y coordinate.",
            "format": "float",
            "type": "number"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1Vertex": {
        "description": "A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image.",
        "properties": {
          "x": {
            "description": "X coordinate.",
            "format": "int32",
            "type": "integer"
          },
          "y": {
            "description": "Y coordinate.",
            "format": "int32",
            "type": "integer"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1TextDetectionParams": {
        "description": "Parameters for text detections. This is used to control TEXT_DETECTION and DOCUMENT_TEXT_DETECTION features.",
        "properties": {
          "advancedOcrOptions": {
            "description": "A list of advanced OCR options to further fine-tune OCR behavior. Current valid values are: - `legacy_layout`: a heuristics layout detection algorithm, which serves as an alternative to the current ML-based layout detection algorithm. Customers can choose the best suitable layout algorithm based on their situation.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "enableTextDetectionConfidenceScore": {
            "description": "By default, Cloud Vision API only includes confidence score for DOCUMENT_TEXT_DETECTION result. Set the flag to true to include confidence score for TEXT_DETECTION as well.",
            "type": "boolean"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1WebDetectionParams": {
        "description": "Parameters for web detection request.",
        "properties": {
          "includeGeoResults": {
            "deprecated": true,
            "description": "This field has no effect on results.",
            "type": "boolean"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1InputConfig": {
        "description": "The desired input location and metadata.",
        "properties": {
          "content": {
            "description": "File content, represented as a stream of bytes. Note: As with all `bytes` fields, protobuffers use a pure binary representation, whereas JSON representations use base64. Currently, this field only works for BatchAnnotateFiles requests. It does not work for AsyncBatchAnnotateFiles requests.",
            "format": "byte",
            "type": "string"
          },
          "gcsSource": {
            "$ref": "#/$defs/GoogleCloudVisionV1p2beta1GcsSource"
          },
          "mimeType": {
            "description": "The type of the file. Currently only \"application/pdf\", \"image/tiff\" and \"image/gif\" are supported. Wildcards are not supported.",
            "type": "string"
          }
        },
        "type": "object"
      },
      "GoogleCloudVisionV1p2beta1GcsSource": {
        "description": "The Google Cloud Storage location where the input will be read from.",
        "properties": {
          "uri": {
            "description": "Google Cloud Storage URI for the input file. This must only be a Google Cloud Storage object. Wildcards are not currently supported.",
            "type": "string"
          }
        },
        "type": "object"
      }
    }
  },
  "handler": "http",
  "request": {
    "method": "POST",
    "url": {
      "$uri": "https://vision.googleapis.com//v1p2beta1/files:annotate{?$.xgafv,access_token,alt,callback,fields,key,oauth_token,prettyPrint,quotaUser,upload_protocol,uploadType}"
    },
    "body": {
      "$": "body",
      "encode": "json"
    }
  },
  "responses": {
    "200": {
      "$encode": "markdown",
      "$block": [
        {
          "$h1": "Object"
        },
        "A list of file annotation responses.",
        "**Key properties:**",
        {
          "$ul": [
            "**responses**: The list of file annotation responses, each response corresponding to each AnnotateFileRequest in BatchAnnotateFilesRequest."
          ]
        },
        {
          "$lang": "json",
          "$code": {
            "$encode": "json",
            "$indent": true,
            "$content": {
              "$": "$.body"
            }
          }
        }
      ]
    }
  }
}
