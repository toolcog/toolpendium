{
  "name": "aiplatform_projects_locations_endpoints_explain",
  "description": "Perform an online explanation. If deployed_model_id is specified, the corresponding DeployModel must have explanation_spec populated. If deployed_model_id is not specified, all DeployedModels must have explanation_spec populated.",
  "parameters": {
    "type": "object",
    "properties": {
      "endpoint": {
        "type": "string",
        "description": "Required. The name of the Endpoint requested to serve the explanation. Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`"
      },
      "$.xgafv": {
        "enum": [
          "1",
          "2"
        ],
        "type": "string",
        "description": "V1 error format."
      },
      "access_token": {
        "type": "string",
        "description": "OAuth access token."
      },
      "alt": {
        "enum": [
          "json",
          "media",
          "proto"
        ],
        "type": "string",
        "description": "Data format for response."
      },
      "callback": {
        "type": "string",
        "description": "JSONP"
      },
      "fields": {
        "type": "string",
        "description": "Selector specifying which fields to include in a partial response."
      },
      "key": {
        "type": "string",
        "description": "API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token."
      },
      "oauth_token": {
        "type": "string",
        "description": "OAuth 2.0 token for the current user."
      },
      "prettyPrint": {
        "type": "boolean",
        "description": "Returns response with indentations and line breaks."
      },
      "quotaUser": {
        "type": "string",
        "description": "Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters."
      },
      "upload_protocol": {
        "type": "string",
        "description": "Upload protocol for media (e.g. \"raw\", \"multipart\")."
      },
      "uploadType": {
        "type": "string",
        "description": "Legacy upload protocol for media (e.g. \"media\", \"multipart\")."
      },
      "body": {
        "$ref": "#/$defs/GoogleCloudAiplatformV1beta1ExplainRequest"
      }
    },
    "required": [
      "endpoint"
    ],
    "$defs": {
      "GoogleCloudAiplatformV1beta1ExplainRequest": {
        "description": "Request message for PredictionService.Explain.",
        "properties": {
          "concurrentExplanationSpecOverride": {
            "additionalProperties": {
              "$ref": "#/$defs/GoogleCloudAiplatformV1beta1ExplanationSpecOverride"
            },
            "description": "Optional. This field is the same as the one above, but supports multiple explanations to occur in parallel. The key can be any string. Each override will be run against the model, then its explanations will be grouped together. Note - these explanations are run **In Addition** to the default Explanation in the deployed model.",
            "type": "object"
          },
          "deployedModelId": {
            "description": "If specified, this ExplainRequest will be served by the chosen DeployedModel, overriding Endpoint.traffic_split.",
            "type": "string"
          },
          "explanationSpecOverride": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1ExplanationSpecOverride"
          },
          "instances": {
            "description": "Required. The instances that are the input to the explanation call. A DeployedModel may have an upper limit on the number of instances it supports per request, and when it is exceeded the explanation call errors in case of AutoML Models, or, in case of customer created Models, the behaviour is as documented by that Model. The schema of any single instance may be specified via Endpoint's DeployedModels' Model's PredictSchemata's instance_schema_uri.",
            "items": {},
            "type": "array"
          },
          "parameters": {
            "description": "The parameters that govern the prediction. The schema of the parameters may be specified via Endpoint's DeployedModels' Model's PredictSchemata's parameters_schema_uri."
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1ExplanationSpecOverride": {
        "description": "The ExplanationSpec entries that can be overridden at online explanation time.",
        "properties": {
          "examplesOverride": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1ExamplesOverride"
          },
          "metadata": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1ExplanationMetadataOverride"
          },
          "parameters": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1ExplanationParameters"
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1ExamplesOverride": {
        "description": "Overrides for example-based explanations.",
        "properties": {
          "crowdingCount": {
            "description": "The number of neighbors to return that have the same crowding tag.",
            "format": "int32",
            "type": "integer"
          },
          "dataFormat": {
            "description": "The format of the data being provided with each call.",
            "enum": [
              "DATA_FORMAT_UNSPECIFIED",
              "INSTANCES",
              "EMBEDDINGS"
            ],
            "type": "string"
          },
          "neighborCount": {
            "description": "The number of neighbors to return.",
            "format": "int32",
            "type": "integer"
          },
          "restrictions": {
            "description": "Restrict the resulting nearest neighbors to respect these constraints.",
            "items": {
              "$ref": "#/$defs/GoogleCloudAiplatformV1beta1ExamplesRestrictionsNamespace"
            },
            "type": "array"
          },
          "returnEmbeddings": {
            "description": "If true, return the embeddings instead of neighbors.",
            "type": "boolean"
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1ExamplesRestrictionsNamespace": {
        "description": "Restrictions namespace for example-based explanations overrides.",
        "properties": {
          "allow": {
            "description": "The list of allowed tags.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "deny": {
            "description": "The list of deny tags.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "namespaceName": {
            "description": "The namespace name.",
            "type": "string"
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1ExplanationMetadataOverride": {
        "description": "The ExplanationMetadata entries that can be overridden at online explanation time.",
        "properties": {
          "inputs": {
            "additionalProperties": {
              "$ref": "#/$defs/GoogleCloudAiplatformV1beta1ExplanationMetadataOverrideInputMetadataOverride"
            },
            "description": "Required. Overrides the input metadata of the features. The key is the name of the feature to be overridden. The keys specified here must exist in the input metadata to be overridden. If a feature is not specified here, the corresponding feature's input metadata is not overridden.",
            "type": "object"
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1ExplanationMetadataOverrideInputMetadataOverride": {
        "description": "The input metadata entries to be overridden.",
        "properties": {
          "inputBaselines": {
            "description": "Baseline inputs for this feature. This overrides the `input_baseline` field of the ExplanationMetadata.InputMetadata object of the corresponding feature's input metadata. If it's not specified, the original baselines are not overridden.",
            "items": {},
            "type": "array"
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1ExplanationParameters": {
        "description": "Parameters to configure explaining for Model's predictions.",
        "properties": {
          "examples": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1Examples"
          },
          "integratedGradientsAttribution": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution"
          },
          "outputIndices": {
            "description": "If populated, only returns attributions that have output_index contained in output_indices. It must be an ndarray of integers, with the same shape of the output it's explaining. If not populated, returns attributions for top_k indices of outputs. If neither top_k nor output_indices is populated, returns the argmax index of the outputs. Only applicable to Models that predict multiple outputs (e,g, multi-class Models that predict multiple classes).",
            "items": {},
            "type": "array"
          },
          "sampledShapleyAttribution": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1SampledShapleyAttribution"
          },
          "topK": {
            "description": "If populated, returns attributions for top K indices of outputs (defaults to 1). Only applies to Models that predicts more than one outputs (e,g, multi-class Models). When set to -1, returns explanations for all outputs.",
            "format": "int32",
            "type": "integer"
          },
          "xraiAttribution": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1XraiAttribution"
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1Examples": {
        "description": "Example-based explainability that returns the nearest neighbors from the provided dataset.",
        "properties": {
          "exampleGcsSource": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource"
          },
          "gcsSource": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1GcsSource"
          },
          "nearestNeighborSearchConfig": {
            "description": "The full configuration for the generated index, the semantics are the same as metadata and should match [NearestNeighborSearchConfig](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config)."
          },
          "neighborCount": {
            "description": "The number of neighbors to return when querying for examples.",
            "format": "int32",
            "type": "integer"
          },
          "presets": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1Presets"
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource": {
        "description": "The Cloud Storage input instances.",
        "properties": {
          "dataFormat": {
            "description": "The format in which instances are given, if not specified, assume it's JSONL format. Currently only JSONL format is supported.",
            "enum": [
              "DATA_FORMAT_UNSPECIFIED",
              "JSONL"
            ],
            "type": "string"
          },
          "gcsSource": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1GcsSource"
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1GcsSource": {
        "description": "The Google Cloud Storage location for the input content.",
        "properties": {
          "uris": {
            "description": "Required. Google Cloud Storage URI(-s) to the input file(s). May contain wildcards. For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.",
            "items": {
              "type": "string"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1Presets": {
        "description": "Preset configuration for example-based explanations",
        "properties": {
          "modality": {
            "description": "The modality of the uploaded model, which automatically configures the distance measurement and feature normalization for the underlying example index and queries. If your model does not precisely fit one of these types, it is okay to choose the closest type.",
            "enum": [
              "MODALITY_UNSPECIFIED",
              "IMAGE",
              "TEXT",
              "TABULAR"
            ],
            "type": "string"
          },
          "query": {
            "description": "Preset option controlling parameters for speed-precision trade-off when querying for examples. If omitted, defaults to `PRECISE`.",
            "enum": [
              "PRECISE",
              "FAST"
            ],
            "type": "string"
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution": {
        "description": "An attribution method that computes the Aumann-Shapley value taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365",
        "properties": {
          "blurBaselineConfig": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1BlurBaselineConfig"
          },
          "smoothGradConfig": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1SmoothGradConfig"
          },
          "stepCount": {
            "description": "Required. The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is within the desired error range. Valid range of its value is [1, 100], inclusively.",
            "format": "int32",
            "type": "integer"
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1BlurBaselineConfig": {
        "description": "Config for blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383",
        "properties": {
          "maxBlurSigma": {
            "description": "The standard deviation of the blur kernel for the blurred baseline. The same blurring parameter is used for both the height and the width dimension. If not set, the method defaults to the zero (i.e. black for images) baseline.",
            "format": "float",
            "type": "number"
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1SmoothGradConfig": {
        "description": "Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf",
        "properties": {
          "featureNoiseSigma": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1FeatureNoiseSigma"
          },
          "noiseSigma": {
            "description": "This is a single float value and will be used to add noise to all the features. Use this field when all features are normalized to have the same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where features are normalized to have 0-mean and 1-variance. Learn more about [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization). For best results the recommended value is about 10% - 20% of the standard deviation of the input feature. Refer to section 3.2 of the SmoothGrad paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1. If the distribution is different per feature, set feature_noise_sigma instead for each feature.",
            "format": "float",
            "type": "number"
          },
          "noisySampleCount": {
            "description": "The number of gradient samples to use for approximation. The higher this number, the more accurate the gradient is, but the runtime complexity increases by this factor as well. Valid range of its value is [1, 50]. Defaults to 3.",
            "format": "int32",
            "type": "integer"
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1FeatureNoiseSigma": {
        "description": "Noise sigma by features. Noise sigma represents the standard deviation of the gaussian kernel that will be used to add noise to interpolated inputs prior to computing gradients.",
        "properties": {
          "noiseSigma": {
            "description": "Noise sigma per feature. No noise is added to features that are not set.",
            "items": {
              "$ref": "#/$defs/GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeature"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeature": {
        "description": "Noise sigma for a single feature.",
        "properties": {
          "name": {
            "description": "The name of the input feature for which noise sigma is provided. The features are defined in explanation metadata inputs.",
            "type": "string"
          },
          "sigma": {
            "description": "This represents the standard deviation of the Gaussian kernel that will be used to add noise to the feature prior to computing gradients. Similar to noise_sigma but represents the noise added to the current feature. Defaults to 0.1.",
            "format": "float",
            "type": "number"
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1SampledShapleyAttribution": {
        "description": "An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features.",
        "properties": {
          "pathCount": {
            "description": "Required. The number of feature permutations to consider when approximating the Shapley values. Valid range of its value is [1, 50], inclusively.",
            "format": "int32",
            "type": "integer"
          }
        },
        "type": "object"
      },
      "GoogleCloudAiplatformV1beta1XraiAttribution": {
        "description": "An explanation method that redistributes Integrated Gradients attributions to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 Supported only by image Models.",
        "properties": {
          "blurBaselineConfig": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1BlurBaselineConfig"
          },
          "smoothGradConfig": {
            "$ref": "#/$defs/GoogleCloudAiplatformV1beta1SmoothGradConfig"
          },
          "stepCount": {
            "description": "Required. The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. Valid range of its value is [1, 100], inclusively.",
            "format": "int32",
            "type": "integer"
          }
        },
        "type": "object"
      }
    }
  },
  "handler": "http",
  "request": {
    "method": "POST",
    "url": {
      "$uri": "https://aiplatform.googleapis.com//v1beta1/{endpoint}:explain{?$.xgafv,access_token,alt,callback,fields,key,oauth_token,prettyPrint,quotaUser,upload_protocol,uploadType}"
    },
    "body": {
      "$": "body",
      "encode": "json"
    }
  },
  "responses": {
    "200": {
      "$encode": "markdown",
      "$block": [
        {
          "$h1": "Object"
        },
        "Response message for PredictionService.Explain.",
        "**Key properties:**",
        {
          "$ul": [
            "**concurrentExplanations**: This field stores the results of the explanations run in parallel with The default explanation strategy/method.",
            "**deployedModelId**: ID of the Endpoint's DeployedModel that served this explanation.",
            "**explanations**: The explanations of the Model's PredictResponse.predictions. It has the same number of elements as instances to be explained.",
            "**predictions**: The predictions that are the output of the predictions call. Same as PredictResponse.predictions."
          ]
        },
        {
          "$lang": "json",
          "$code": {
            "$encode": "json",
            "$indent": true,
            "$content": {
              "$": "$.body"
            }
          }
        }
      ]
    }
  }
}
