{
  "name": "GetFaceDetection",
  "description": "<p>Gets face detection results for a Amazon Rekognition Video analysis started by <a>StartFaceDetection</a>.</p> <p>Face detection with Amazon Rekognition Video is an asynchronous operation. You start face detection by calling <a>StartFaceDetection</a> which returns a job identifier (<code>JobId</code>). When the face detection operation finishes, Amazon Rekognition Video publishes a completion status to the Amazon Simple Notification Service topic registered in the initial call to <code>StartFaceDetection</code>. To get the results of the face detection operation, first check that the status value published to the Amazon SNS topic is <code>SUCCEEDED</code>. If so, call <a>GetFaceDetection</a> and pass the job identifier (<code>JobId</code>) from the initial call to <code>StartFaceDetection</code>.</p> <p> <code>GetFaceDetection</code> returns an array of detected faces (<code>Faces</code>) sorted by the time the faces were detected. </p> <p>Use MaxResults parameter to limit the number of labels returned. If there are more results than specified in <code>MaxResults</code>, the value of <code>NextToken</code> in the operation response contains a pagination token for getting the next set of results. To get the next page of results, call <code>GetFaceDetection</code> and populate the <code>NextToken</code> request parameter with the token value returned from the previous call to <code>GetFaceDetection</code>.</p> <p>Note that for the <code>GetFaceDetection</code> operation, the returned values for <code>FaceOccluded</code> and <code>EyeDirection</code> will always be \"null\".</p>",
  "parameters": {
    "type": "object",
    "properties": {
      "MaxResults": {
        "type": "string",
        "description": "Pagination limit"
      },
      "NextToken": {
        "type": "string",
        "description": "Pagination token"
      },
      "X-Amz-Target": {
        "type": "string",
        "enum": [
          "RekognitionService.GetFaceDetection"
        ]
      },
      "X-Amz-Content-Sha256": {
        "type": "string"
      },
      "X-Amz-Date": {
        "type": "string"
      },
      "X-Amz-Algorithm": {
        "type": "string"
      },
      "X-Amz-Credential": {
        "type": "string"
      },
      "X-Amz-Security-Token": {
        "type": "string"
      },
      "X-Amz-Signature": {
        "type": "string"
      },
      "X-Amz-SignedHeaders": {
        "type": "string"
      },
      "body": {
        "$ref": "#/$defs/GetFaceDetectionRequest"
      }
    },
    "required": [
      "X-Amz-Target",
      "body"
    ],
    "$defs": {
      "GetFaceDetectionRequest": {
        "type": "object",
        "required": [
          "JobId"
        ],
        "title": "GetFaceDetectionRequest",
        "properties": {
          "JobId": {
            "allOf": [
              {
                "$ref": "#/$defs/JobId"
              },
              {
                "description": "Unique identifier for the face detection job. The <code>JobId</code> is returned from <code>StartFaceDetection</code>."
              }
            ]
          },
          "MaxResults": {
            "allOf": [
              {
                "$ref": "#/$defs/MaxResults"
              },
              {
                "description": "Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000."
              }
            ]
          },
          "NextToken": {
            "allOf": [
              {
                "$ref": "#/$defs/PaginationToken"
              },
              {
                "description": "If the previous response was incomplete (because there are more faces to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of faces."
              }
            ]
          }
        }
      },
      "JobId": {
        "type": "string",
        "pattern": "^[a-zA-Z0-9-_]+$",
        "minLength": 1,
        "maxLength": 64
      },
      "MaxResults": {
        "type": "integer",
        "minimum": 1
      },
      "PaginationToken": {
        "type": "string",
        "maxLength": 255
      }
    }
  },
  "handler": "http",
  "request": {
    "method": "POST",
    "url": {
      "$uri": "http://rekognition.us-east-1.amazonaws.com/#X-Amz-Target=RekognitionService.GetFaceDetection{?MaxResults,NextToken}"
    },
    "headers": {
      "X-Amz-Target": {
        "$": "X-Amz-Target"
      },
      "X-Amz-Content-Sha256": {
        "$": "X-Amz-Content-Sha256"
      },
      "X-Amz-Date": {
        "$": "X-Amz-Date"
      },
      "X-Amz-Algorithm": {
        "$": "X-Amz-Algorithm"
      },
      "X-Amz-Credential": {
        "$": "X-Amz-Credential"
      },
      "X-Amz-Security-Token": {
        "$": "X-Amz-Security-Token"
      },
      "X-Amz-Signature": {
        "$": "X-Amz-Signature"
      },
      "X-Amz-SignedHeaders": {
        "$": "X-Amz-SignedHeaders"
      }
    },
    "body": {
      "$": "body",
      "encode": "json"
    }
  },
  "responses": {
    "200": {
      "$encode": "markdown",
      "$block": [
        {
          "$h1": "Object"
        },
        "**Key properties:**",
        {
          "$ul": [
            "**JobStatus**",
            "**StatusMessage**",
            "**VideoMetadata**",
            "**NextToken**",
            "**Faces**",
            "**JobId**",
            [
              "**Video**: Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as <a>StartLabelDetection</a> use <code>Video</code> to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.",
              {
                "$ul": [
                  "**S3Object**"
                ]
              }
            ],
            "**JobTag**"
          ]
        },
        {
          "$lang": "json",
          "$code": {
            "$encode": "json",
            "$indent": true,
            "$content": {
              "$": "$.body"
            }
          }
        }
      ]
    },
    "480": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "481": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "482": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "483": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "484": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "485": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "486": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    }
  }
}
