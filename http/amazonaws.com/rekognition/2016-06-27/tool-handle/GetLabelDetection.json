{
  "name": "GetLabelDetection",
  "description": "<p>Gets the label detection results of a Amazon Rekognition Video analysis started by <a>StartLabelDetection</a>. </p> <p>The label detection operation is started by a call to <a>StartLabelDetection</a> which returns a job identifier (<code>JobId</code>). When the label detection operation finishes, Amazon Rekognition publishes a completion status to the Amazon Simple Notification Service topic registered in the initial call to <code>StartlabelDetection</code>. </p> <p>To get the results of the label detection operation, first check that the status value published to the Amazon SNS topic is <code>SUCCEEDED</code>. If so, call <a>GetLabelDetection</a> and pass the job identifier (<code>JobId</code>) from the initial call to <code>StartLabelDetection</code>.</p> <p> <code>GetLabelDetection</code> returns an array of detected labels (<code>Labels</code>) sorted by the time the labels were detected. You can also sort by the label name by specifying <code>NAME</code> for the <code>SortBy</code> input parameter. If there is no <code>NAME</code> specified, the default sort is by timestamp.</p> <p>You can select how results are aggregated by using the <code>AggregateBy</code> input parameter. The default aggregation method is <code>TIMESTAMPS</code>. You can also aggregate by <code>SEGMENTS</code>, which aggregates all instances of labels detected in a given segment. </p> <p>The returned Labels array may include the following attributes:</p> <ul> <li> <p>Name - The name of the detected label.</p> </li> <li> <p>Confidence - The level of confidence in the label assigned to a detected object. </p> </li> <li> <p>Parents - The ancestor labels for a detected label. GetLabelDetection returns a hierarchical taxonomy of detected labels. For example, a detected car might be assigned the label car. The label car has two parent labels: Vehicle (its parent) and Transportation (its grandparent). The response includes the all ancestors for a label, where every ancestor is a unique label. In the previous example, Car, Vehicle, and Transportation are returned as unique labels in the response. </p> </li> <li> <p> Aliases - Possible Aliases for the label. </p> </li> <li> <p>Categories - The label categories that the detected label belongs to.</p> </li> <li> <p>BoundingBox — Bounding boxes are described for all instances of detected common object labels, returned in an array of Instance objects. An Instance object contains a BoundingBox object, describing the location of the label on the input image. It also includes the confidence for the accuracy of the detected bounding box.</p> </li> <li> <p>Timestamp - Time, in milliseconds from the start of the video, that the label was detected. For aggregation by <code>SEGMENTS</code>, the <code>StartTimestampMillis</code>, <code>EndTimestampMillis</code>, and <code>DurationMillis</code> structures are what define a segment. Although the “Timestamp” structure is still returned with each label, its value is set to be the same as <code>StartTimestampMillis</code>.</p> </li> </ul> <p>Timestamp and Bounding box information are returned for detected Instances, only if aggregation is done by <code>TIMESTAMPS</code>. If aggregating by <code>SEGMENTS</code>, information about detected instances isn’t returned. </p> <p>The version of the label model used for the detection is also returned.</p> <p> <b>Note <code>DominantColors</code> isn't returned for <code>Instances</code>, although it is shown as part of the response in the sample seen below.</b> </p> <p>Use <code>MaxResults</code> parameter to limit the number of labels returned. If there are more results than specified in <code>MaxResults</code>, the value of <code>NextToken</code> in the operation response contains a pagination token for getting the next set of results. To get the next page of results, call <code>GetlabelDetection</code> and populate the <code>NextToken</code> request parameter with the token value returned from the previous call to <code>GetLabelDetection</code>.</p>",
  "parameters": {
    "type": "object",
    "properties": {
      "MaxResults": {
        "type": "string",
        "description": "Pagination limit"
      },
      "NextToken": {
        "type": "string",
        "description": "Pagination token"
      },
      "X-Amz-Target": {
        "type": "string",
        "enum": [
          "RekognitionService.GetLabelDetection"
        ]
      },
      "X-Amz-Content-Sha256": {
        "type": "string"
      },
      "X-Amz-Date": {
        "type": "string"
      },
      "X-Amz-Algorithm": {
        "type": "string"
      },
      "X-Amz-Credential": {
        "type": "string"
      },
      "X-Amz-Security-Token": {
        "type": "string"
      },
      "X-Amz-Signature": {
        "type": "string"
      },
      "X-Amz-SignedHeaders": {
        "type": "string"
      },
      "body": {
        "$ref": "#/$defs/GetLabelDetectionRequest"
      }
    },
    "required": [
      "X-Amz-Target",
      "body"
    ],
    "$defs": {
      "GetLabelDetectionRequest": {
        "type": "object",
        "required": [
          "JobId"
        ],
        "title": "GetLabelDetectionRequest",
        "properties": {
          "JobId": {
            "allOf": [
              {
                "$ref": "#/$defs/JobId"
              },
              {
                "description": "Job identifier for the label detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartlabelDetection</code>."
              }
            ]
          },
          "MaxResults": {
            "allOf": [
              {
                "$ref": "#/$defs/MaxResults"
              },
              {
                "description": "Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000."
              }
            ]
          },
          "NextToken": {
            "allOf": [
              {
                "$ref": "#/$defs/PaginationToken"
              },
              {
                "description": "If the previous response was incomplete (because there are more labels to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of labels. "
              }
            ]
          },
          "SortBy": {
            "allOf": [
              {
                "$ref": "#/$defs/LabelDetectionSortBy"
              },
              {
                "description": "Sort to use for elements in the <code>Labels</code> array. Use <code>TIMESTAMP</code> to sort array elements by the time labels are detected. Use <code>NAME</code> to alphabetically group elements for a label together. Within each label group, the array element are sorted by detection confidence. The default sort is by <code>TIMESTAMP</code>."
              }
            ]
          },
          "AggregateBy": {
            "allOf": [
              {
                "$ref": "#/$defs/LabelDetectionAggregateBy"
              },
              {
                "description": "Defines how to aggregate the returned results. Results can be aggregated by timestamps or segments."
              }
            ]
          }
        }
      },
      "JobId": {
        "type": "string",
        "pattern": "^[a-zA-Z0-9-_]+$",
        "minLength": 1,
        "maxLength": 64
      },
      "MaxResults": {
        "type": "integer",
        "minimum": 1
      },
      "PaginationToken": {
        "type": "string",
        "maxLength": 255
      },
      "LabelDetectionSortBy": {
        "type": "string",
        "enum": [
          "NAME",
          "TIMESTAMP"
        ]
      },
      "LabelDetectionAggregateBy": {
        "type": "string",
        "enum": [
          "TIMESTAMPS",
          "SEGMENTS"
        ]
      }
    }
  },
  "handler": "http",
  "request": {
    "method": "POST",
    "url": {
      "$uri": "http://rekognition.us-east-1.amazonaws.com/#X-Amz-Target=RekognitionService.GetLabelDetection{?MaxResults,NextToken}"
    },
    "headers": {
      "X-Amz-Target": {
        "$": "X-Amz-Target"
      },
      "X-Amz-Content-Sha256": {
        "$": "X-Amz-Content-Sha256"
      },
      "X-Amz-Date": {
        "$": "X-Amz-Date"
      },
      "X-Amz-Algorithm": {
        "$": "X-Amz-Algorithm"
      },
      "X-Amz-Credential": {
        "$": "X-Amz-Credential"
      },
      "X-Amz-Security-Token": {
        "$": "X-Amz-Security-Token"
      },
      "X-Amz-Signature": {
        "$": "X-Amz-Signature"
      },
      "X-Amz-SignedHeaders": {
        "$": "X-Amz-SignedHeaders"
      }
    },
    "body": {
      "$": "body",
      "encode": "json"
    }
  },
  "responses": {
    "200": {
      "$encode": "markdown",
      "$block": [
        {
          "$h1": "Object"
        },
        "**Key properties:**",
        {
          "$ul": [
            "**JobStatus**",
            "**StatusMessage**",
            "**VideoMetadata**",
            "**NextToken**",
            "**Labels**",
            "**LabelModelVersion**",
            "**JobId**",
            [
              "**Video**: Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as <a>StartLabelDetection</a> use <code>Video</code> to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.",
              {
                "$ul": [
                  "**S3Object**"
                ]
              }
            ],
            "**JobTag**",
            "**GetRequestMetadata**"
          ]
        },
        {
          "$lang": "json",
          "$code": {
            "$encode": "json",
            "$indent": true,
            "$content": {
              "$": "$.body"
            }
          }
        }
      ]
    },
    "480": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "481": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "482": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "483": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "484": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "485": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "486": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    }
  }
}
