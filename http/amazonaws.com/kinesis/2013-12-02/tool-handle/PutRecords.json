{
  "name": "PutRecords",
  "description": "<p>Writes multiple data records into a Kinesis data stream in a single call (also referred to as a <code>PutRecords</code> request). Use this operation to send data into the stream for data ingestion and processing. </p> <note> <p>When invoking this API, it is recommended you use the <code>StreamARN</code> input parameter rather than the <code>StreamName</code> input parameter.</p> </note> <p>Each <code>PutRecords</code> request can support up to 500 records. Each record in the request can be as large as 1 MiB, up to a limit of 5 MiB for the entire request, including partition keys. Each shard can support writes up to 1,000 records per second, up to a maximum data write total of 1 MiB per second.</p> <p>You must specify the name of the stream that captures, stores, and transports the data; and an array of request <code>Records</code>, with each record in the array requiring a partition key and data blob. The record size limit applies to the total size of the partition key and data blob.</p> <p>The data blob can be any type of data; for example, a segment from a log file, geographic/location data, website clickstream data, and so on.</p> <p>The partition key is used by Kinesis Data Streams as input to a hash function that maps the partition key and associated data to a specific shard. An MD5 hash function is used to map partition keys to 128-bit integer values and to map associated data records to shards. As a result of this hashing mechanism, all data records with the same partition key map to the same shard within the stream. For more information, see <a href=\"https://docs.aws.amazon.com/kinesis/latest/dev/developing-producers-with-sdk.html#kinesis-using-sdk-java-add-data-to-stream\">Adding Data to a Stream</a> in the <i>Amazon Kinesis Data Streams Developer Guide</i>.</p> <p>Each record in the <code>Records</code> array may include an optional parameter, <code>ExplicitHashKey</code>, which overrides the partition key to shard mapping. This parameter allows a data producer to determine explicitly the shard where the record is stored. For more information, see <a href=\"https://docs.aws.amazon.com/kinesis/latest/dev/developing-producers-with-sdk.html#kinesis-using-sdk-java-putrecords\">Adding Multiple Records with PutRecords</a> in the <i>Amazon Kinesis Data Streams Developer Guide</i>.</p> <p>The <code>PutRecords</code> response includes an array of response <code>Records</code>. Each record in the response array directly correlates with a record in the request array using natural ordering, from the top to the bottom of the request and response. The response <code>Records</code> array always includes the same number of records as the request array.</p> <p>The response <code>Records</code> array includes both successfully and unsuccessfully processed records. Kinesis Data Streams attempts to process all records in each <code>PutRecords</code> request. A single record failure does not stop the processing of subsequent records. As a result, PutRecords doesn't guarantee the ordering of records. If you need to read records in the same order they are written to the stream, use <a>PutRecord</a> instead of <code>PutRecords</code>, and write to the same shard.</p> <p>A successfully processed record includes <code>ShardId</code> and <code>SequenceNumber</code> values. The <code>ShardId</code> parameter identifies the shard in the stream where the record is stored. The <code>SequenceNumber</code> parameter is an identifier assigned to the put record, unique to all records in the stream.</p> <p>An unsuccessfully processed record includes <code>ErrorCode</code> and <code>ErrorMessage</code> values. <code>ErrorCode</code> reflects the type of error and can be one of the following values: <code>ProvisionedThroughputExceededException</code> or <code>InternalFailure</code>. <code>ErrorMessage</code> provides more detailed information about the <code>ProvisionedThroughputExceededException</code> exception including the account ID, stream name, and shard ID of the record that was throttled. For more information about partially successful responses, see <a href=\"https://docs.aws.amazon.com/kinesis/latest/dev/kinesis-using-sdk-java-add-data-to-stream.html#kinesis-using-sdk-java-putrecords\">Adding Multiple Records with PutRecords</a> in the <i>Amazon Kinesis Data Streams Developer Guide</i>.</p> <important> <p>After you write a record to a stream, you cannot modify that record or its order within the stream.</p> </important> <p>By default, data records are accessible for 24 hours from the time that they are added to a stream. You can use <a>IncreaseStreamRetentionPeriod</a> or <a>DecreaseStreamRetentionPeriod</a> to modify this retention period.</p>",
  "parameters": {
    "type": "object",
    "properties": {
      "X-Amz-Target": {
        "type": "string",
        "enum": [
          "Kinesis_20131202.PutRecords"
        ]
      },
      "X-Amz-Content-Sha256": {
        "type": "string"
      },
      "X-Amz-Date": {
        "type": "string"
      },
      "X-Amz-Algorithm": {
        "type": "string"
      },
      "X-Amz-Credential": {
        "type": "string"
      },
      "X-Amz-Security-Token": {
        "type": "string"
      },
      "X-Amz-Signature": {
        "type": "string"
      },
      "X-Amz-SignedHeaders": {
        "type": "string"
      },
      "body": {
        "$ref": "#/$defs/PutRecordsInput"
      }
    },
    "required": [
      "X-Amz-Target",
      "body"
    ],
    "$defs": {
      "PutRecordsInput": {
        "type": "object",
        "required": [
          "Records"
        ],
        "title": "PutRecordsInput",
        "properties": {
          "Records": {
            "allOf": [
              {
                "$ref": "#/$defs/PutRecordsRequestEntryList"
              },
              {
                "description": "The records associated with the request."
              }
            ]
          },
          "StreamName": {
            "allOf": [
              {
                "$ref": "#/$defs/StreamName"
              },
              {
                "description": "The stream name associated with the request."
              }
            ]
          },
          "StreamARN": {
            "allOf": [
              {
                "$ref": "#/$defs/StreamARN"
              },
              {
                "description": "The ARN of the stream."
              }
            ]
          }
        },
        "description": "A <code>PutRecords</code> request."
      },
      "PutRecordsRequestEntryList": {
        "type": "array",
        "items": {
          "$ref": "#/$defs/PutRecordsRequestEntry"
        },
        "minItems": 1,
        "maxItems": 500
      },
      "PutRecordsRequestEntry": {
        "type": "object",
        "required": [
          "Data",
          "PartitionKey"
        ],
        "properties": {
          "Data": {
            "allOf": [
              {
                "$ref": "#/$defs/Data"
              },
              {
                "description": "The data blob to put into the record, which is base64-encoded when the blob is serialized. When the data blob (the payload before base64-encoding) is added to the partition key size, the total size must not exceed the maximum record size (1 MiB)."
              }
            ]
          },
          "ExplicitHashKey": {
            "allOf": [
              {
                "$ref": "#/$defs/HashKey"
              },
              {
                "description": "The hash value used to determine explicitly the shard that the data record is assigned to by overriding the partition key hash."
              }
            ]
          },
          "PartitionKey": {
            "allOf": [
              {
                "$ref": "#/$defs/PartitionKey"
              },
              {
                "description": "Determines which shard in the stream the data record is assigned to. Partition keys are Unicode strings with a maximum length limit of 256 characters for each key. Amazon Kinesis Data Streams uses the partition key as input to a hash function that maps the partition key and associated data to a specific shard. Specifically, an MD5 hash function is used to map partition keys to 128-bit integer values and to map associated data records to shards. As a result of this hashing mechanism, all data records with the same partition key map to the same shard within the stream."
              }
            ]
          }
        },
        "description": "Represents the output for <code>PutRecords</code>."
      },
      "Data": {
        "type": "string",
        "minLength": 0,
        "maxLength": 1048576
      },
      "HashKey": {
        "type": "string",
        "pattern": "0|([1-9]\\d{0,38})"
      },
      "PartitionKey": {
        "type": "string",
        "minLength": 1,
        "maxLength": 256
      },
      "StreamName": {
        "type": "string",
        "pattern": "[a-zA-Z0-9_.-]+",
        "minLength": 1,
        "maxLength": 128
      },
      "StreamARN": {
        "type": "string",
        "pattern": "arn:aws.*:kinesis:.*:\\d{12}:stream/\\S+",
        "minLength": 1,
        "maxLength": 2048
      }
    }
  },
  "handler": "http",
  "request": {
    "method": "POST",
    "url": {
      "$uri": "http://kinesis.us-east-1.amazonaws.com/#X-Amz-Target=Kinesis_20131202.PutRecords"
    },
    "headers": {
      "X-Amz-Target": {
        "$": "X-Amz-Target"
      },
      "X-Amz-Content-Sha256": {
        "$": "X-Amz-Content-Sha256"
      },
      "X-Amz-Date": {
        "$": "X-Amz-Date"
      },
      "X-Amz-Algorithm": {
        "$": "X-Amz-Algorithm"
      },
      "X-Amz-Credential": {
        "$": "X-Amz-Credential"
      },
      "X-Amz-Security-Token": {
        "$": "X-Amz-Security-Token"
      },
      "X-Amz-Signature": {
        "$": "X-Amz-Signature"
      },
      "X-Amz-SignedHeaders": {
        "$": "X-Amz-SignedHeaders"
      }
    },
    "body": {
      "$": "body",
      "encode": "json"
    }
  },
  "responses": {
    "200": {
      "$encode": "markdown",
      "$block": [
        {
          "$h1": "Object"
        },
        " <code>PutRecords</code> results.",
        "**Key properties:**",
        {
          "$ul": [
            "**FailedRecordCount**",
            "**Records**",
            "**EncryptionType**"
          ]
        },
        {
          "$lang": "json",
          "$code": {
            "$encode": "json",
            "$indent": true,
            "$content": {
              "$": "$.body"
            }
          }
        }
      ]
    },
    "480": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "481": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "482": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "483": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "484": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "485": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "486": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "487": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "488": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    },
    "489": {
      "$encode": "markdown",
      "$lang": "json",
      "$code": {
        "$encode": "json",
        "$indent": true,
        "$content": {
          "$": "$.body"
        }
      }
    }
  }
}
